{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c025dde5",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning\n",
    "- hyper parameter: 모델 설정과 관련해 직접 지정할 수 있는 매개변수\n",
    "- model parameter: 회귀계수(가중치), 절편 등 모델의 학습 대상이 되는 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3cd9a",
   "metadata": {},
   "source": [
    "##### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f964beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b379c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'n_neighbors': 7}\n",
      "최적의 모델 객체: KNeighborsClassifier(n_neighbors=7)\n",
      "최적화된 점수: 0.9800000000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: range(1, 13, 2)}, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">KNeighborsClassifier()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;n_neighbors&#x27;: range(1, 13, 2)}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;accuracy&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: KNeighborsClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>KNeighborsClassifier(n_neighbors=7)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_neighbors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_neighbors&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">weights&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;uniform&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('leaf_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">leaf_size&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('p',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">p&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;minkowski&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric_params',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric_params&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 13, 2)}, scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': range(1, 13, 2), #1, 3, 5, 7, 9, 11\n",
    "\n",
    "}\n",
    "# 테스트할 파라미터 값 저장한 dict 생성\n",
    "\n",
    "grid = GridSearchCV(knn, params, scoring='accuracy', cv=5)\n",
    "# estimator: 검증에 사용할 모델 이름\n",
    "# param_grid: 테스트할 때 하이퍼 파라미터로 넣을 것들(dict형으로)\n",
    "# scoring: 평가 지표. accuracy, precision, recall, f1\n",
    "# cv: 검증 반복 횟수\n",
    "\n",
    "# X, y 데이터 들어가지 않음. GridSearchCV는 하이퍼 파라미터의 변화에 따라 검증 수행하므로\n",
    "\n",
    "grid.fit(iris_input, iris_target)\n",
    "# 데이터 학습\n",
    "\n",
    "print('최적의 파라미터:', grid.best_params_)\n",
    "print('최적의 모델 객체:', grid.best_estimator_)\n",
    "# 최적 파라미터로 '학습'이 된 모델 객체 반환.(.score(), .predict() 가능) cross_validate와 다른 점임\n",
    "\n",
    "print('최적화된 점수:', grid.best_score_)\n",
    "# 교차 검증 실행한 것 중 가장 높은 점수. knn.score()와 다를 수 있음\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb9e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "# best_knn.fit(iris_input, iris_target)\n",
    "best_knn.score(iris_input, iris_target)\n",
    "best_knn.predict(iris_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333a94e",
   "metadata": {},
   "source": [
    "##### RandomSearchCV\n",
    "- 하이퍼 파라미터의 값 목록이나 값의 범위를 제공하는데, 이 범위 중에 랜덤하게 값 뽑아내 최적의 하이퍼 파라미터 조합을 찾음\n",
    "    - 탐색 범위가 넓을 때 '짧은 시간' 내 좋은 결과 얻을 수 있음\n",
    "    - 랜덤하게 값을 추출해 계산하므로 전역 최적값 놓칠 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터: {'n_neighbors': 31}\n",
      "최적 모델 객체: KNeighborsClassifier(n_neighbors=31)\n",
      "최적화된 성능 점수: 0.9333333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 181, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 509, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 567, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 891, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 923, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 633, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 979, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 319, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:953: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 942, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 492, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 446, in score\n",
      "    return super().score(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py\", line 548, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 262, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 371, in predict_proba\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 307, n_samples_fit = 120, n_samples = 30\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.93333333\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 생성\n",
    "params = {\n",
    "    'n_neighbors': range(1, 1000, 2)\n",
    "}\n",
    "rd_search = RandomizedSearchCV(knn, params, cv=5, n_iter=10, random_state=0)\n",
    "# esimator: 검증할 모델 객체\n",
    "# param_distribution: 하이퍼 파라미터 dictionary\n",
    "# n_iter: 탐색할 최적의 하이퍼 파라미터 조합 개수. 기본값은 10.\n",
    "        # 이 값이 클수록 오래 걸림 (탐색할 게 많으므로) 값이 낮을수록 최적 조합 찾을 가능성 저하\n",
    "        # 딕셔너리로 넘긴 하이퍼 파라미터는 500개여도 열 번만 수행\n",
    "rd_search.fit(iris_input, iris_target)\n",
    "\n",
    "print('최적 파라미터:', rd_search.best_params_)\n",
    "print('최적 모델 객체:', rd_search.best_estimator_)\n",
    "print('최적화된 성능 점수:', rd_search.best_score_)\n",
    "# 최적 파라미터: {'n_neighbors': 31}\n",
    "# 최적 모델 객체: KNeighborsClassifier(n_neighbors=31)\n",
    "# 최적화된 성능 점수: 0.9333333333333332\n",
    "\n",
    "# 위의 n_neighbors = 7이 더 성능이 높음. 그러나 n_iters=10이므로 찾지 못했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c57945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00040092, 0.00040364, 0.00019975, 0.        , 0.0003994 ,\n",
       "        0.00039592, 0.0006001 , 0.00020008, 0.00039988, 0.        ]),\n",
       " 'std_fit_time': array([0.00049104, 0.00049439, 0.00039949, 0.        , 0.00048916,\n",
       "        0.00048494, 0.00048998, 0.00040016, 0.00048975, 0.        ]),\n",
       " 'mean_score_time': array([0.0007997 , 0.00040255, 0.00059772, 0.00059695, 0.00020008,\n",
       "        0.0011694 , 0.00039988, 0.00039988, 0.00040011, 0.00100346]),\n",
       " 'std_score_time': array([3.99854767e-04, 4.93270227e-04, 4.88259550e-04, 4.87443281e-04,\n",
       "        4.00161743e-04, 3.29536409e-04, 4.89745640e-04, 4.89745664e-04,\n",
       "        4.90037926e-04, 7.57165758e-06]),\n",
       " 'param_n_neighbors': masked_array(data=[181, 509, 567, 891, 923, 31, 633, 979, 319, 307],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'n_neighbors': 181},\n",
       "  {'n_neighbors': 509},\n",
       "  {'n_neighbors': 567},\n",
       "  {'n_neighbors': 891},\n",
       "  {'n_neighbors': 923},\n",
       "  {'n_neighbors': 31},\n",
       "  {'n_neighbors': 633},\n",
       "  {'n_neighbors': 979},\n",
       "  {'n_neighbors': 319},\n",
       "  {'n_neighbors': 307}],\n",
       " 'split0_test_score': array([nan, nan, nan, nan, nan, 0.9, nan, nan, nan, nan]),\n",
       " 'split1_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "        0.96666667,        nan,        nan,        nan,        nan]),\n",
       " 'split2_test_score': array([nan, nan, nan, nan, nan, 0.9, nan, nan, nan, nan]),\n",
       " 'split3_test_score': array([nan, nan, nan, nan, nan, 0.9, nan, nan, nan, nan]),\n",
       " 'split4_test_score': array([nan, nan, nan, nan, nan,  1., nan, nan, nan, nan]),\n",
       " 'mean_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "        0.93333333,        nan,        nan,        nan,        nan]),\n",
       " 'std_test_score': array([      nan,       nan,       nan,       nan,       nan, 0.0421637,\n",
       "              nan,       nan,       nan,       nan]),\n",
       " 'rank_test_score': array([2, 2, 2, 2, 2, 1, 2, 2, 2, 2], dtype=int32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dict = rd_search.cv_results_\n",
    "cv_dict\n",
    "# 어떤 하이퍼 파라미터 10개를 선정해서 검증했는지, 시간은 얼마나 걸렸는지 등을 딕셔너리 형태로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f63d5c",
   "metadata": {},
   "source": [
    "---\n",
    "##### HyperOpt\n",
    "- 자동 파라미터 튜닝 라이브러리 (알아서 최적 파라미터 찾아줌)\n",
    "- 베이지안 정리 -> 베이지안 최적화 기법으로 사용\n",
    "- 베이지안 최적화: 고비용의 black-box 함수를 최소화하기 위한 탐색 알고리즘. 최소한의 시도로 최적 값을 찾는 게 목표임\n",
    "\n",
    "https://hyperopt.github.io/hyperopt/tutorials/01.BasicTutorial/#01-basic-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c0798",
   "metadata": {},
   "source": [
    "**hyper.hp클래스**\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>함수명</th>\n",
    "      <th>설명</th>\n",
    "      <th>사용 방법</th>\n",
    "      <th>예시 코드</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>hp.uniform</td>\n",
    "      <td>연속적인 실수 값 샘플링</td>\n",
    "      <td>hp.uniform(label, low, high)</td>\n",
    "      <td><code>hp.uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.quniform</td>\n",
    "      <td>연속적이지만 일정 간격(q)을 갖는 값 샘플링</td>\n",
    "      <td>hp.quniform(label, low, high, q)</td>\n",
    "      <td><code>hp.quniform('num_layers', 1, 5, 1)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.loguniform</td>\n",
    "      <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "      <td>hp.loguniform(label, low, high)</td>\n",
    "      <td><code>hp.loguniform('reg_param', -3, 0)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.randint</td>\n",
    "      <td>정수 값 샘플링</td>\n",
    "      <td>hp.randint(label, upper)</td>\n",
    "      <td><code>hp.randint('num_trees', 1, 100)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.choice</td>\n",
    "      <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "      <td>hp.choice(label, options)</td>\n",
    "      <td><code>hp.choice('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.normal</td>\n",
    "      <td>정규분포에서 값 샘플링</td>\n",
    "      <td>hp.normal(label, mean, std)</td>\n",
    "      <td><code>hp.normal('dropout_rate', 0.3, 0.05)</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>hp.lognormal</td>\n",
    "      <td>로그 정규분포에서 값 샘플링</td>\n",
    "      <td>hp.lognormal(label, mean, std)</td>\n",
    "      <td><code>hp.lognormal('scale', 0, 1)</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52c5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (1.16.1)\n",
      "Requirement already satisfied: six in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from hyperopt) (1.17.0)\n",
      "Collecting networkx>=2.2 (from hyperopt)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting tqdm (from hyperopt)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting cloudpickle (from hyperopt)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 16.9 MB/s  0:00:00\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 118.2 MB/s  0:00:00\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: py4j, tqdm, networkx, future, cloudpickle, hyperopt\n",
      "\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ---------------------------------------- 0/6 [py4j]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------ --------------------------------- 1/6 [tqdm]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------- ------------------- 3/6 [future]\n",
      "   -------------------------- ------------- 4/6 [cloudpickle]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   --------------------------------- ------ 5/6 [hyperopt]\n",
      "   ---------------------------------------- 6/6 [hyperopt]\n",
      "\n",
      "Successfully installed cloudpickle-3.1.1 future-1.0.0 hyperopt-0.2.7 networkx-3.5 py4j-0.10.9.9 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# 검색 공간\n",
    "search_space = {\n",
    "    'x': hp.quniform('x', -10, 10, 1),  # -10, -9, ... , 9, 10\n",
    "    'y': hp.quniform('y', -15, 15, 1)\n",
    "    # x, y는 num_layers(label) = 파라미터 명으로 들어가야 할 곳\n",
    "    # 즉, 'x'의 value는 x라는 label로 -10~10까지 갖고 있음\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e497ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "# 목적 함수 (최적화할 목표 함수) 생성\n",
    "def objective(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    \n",
    "    return {\n",
    "        'loss': x**2 + 20 * y,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "        # 평가가 성공적으로 수행이 되었는지 알려줌 (오류가 발생하지 않으면 STATUS OK 반환)\n",
    "    } # x^2 + 20y (로스값) 다항식 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bb0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 87.05trial/s, best loss: -300.0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': np.float64(-0.0), 'y': np.float64(-15.0)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "# 최적 하이퍼 파라미터를 탐색하는 과정을 저장하는 객체\n",
    "\n",
    "best_var = fmin(\n",
    "    fn=objective,           # 목적함수 만든 메서드 전달(로스 함수의 최솟값 찾아야 함)\n",
    "    space=search_space,     # 검색 공간 (최솟값 찾아주는 공간)\n",
    "    algo=tpe.suggest,       # 탐색할 때 tpe.suggest 알고리즘 사용\n",
    "                                # tpe.suggest = 베이지안 최적화 적용\n",
    "    max_evals=500,           # 목적 함수에서 최솟값 찾을 때 반복 횟수 500번\n",
    "                                # 500개의 최솟값 찾는 게 아닌, 최솟값 찾기 시도를 500번 함\n",
    "                                # x, y 파라미터 모두 검사하려면 600번\n",
    "    trials = trials         # 탐색 과정 저장\n",
    ")\n",
    "# fmin(): 목적 함수의 최소값을 찾는 메서드\n",
    "best_var\n",
    "# 500번 수행 뒤 함수가 최솟값을 가질 때 x, y값 반환 (0, -15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(3.0)],\n",
       " 'y': [np.float64(1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-0.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(8.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(3.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-4.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-5.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(1.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(7.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(4.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(2.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-3.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-2.0),\n",
       "  np.float64(-8.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-6.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-7.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-11.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-1.0),\n",
       "  np.float64(-12.0),\n",
       "  np.float64(12.0),\n",
       "  np.float64(5.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-13.0),\n",
       "  np.float64(-15.0),\n",
       "  np.float64(-9.0),\n",
       "  np.float64(-14.0),\n",
       "  np.float64(-10.0),\n",
       "  np.float64(-12.0)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 탐색 과정에서 목적함수의 반환값을 저장 (loss함수값+실행 상태)\n",
    "trials.results\n",
    "\n",
    "# 각 loss함수값이 나왔을 때 x, y(하이퍼파라미터)에 넣은 값(500번 시도할 때 넣은 값)을 dict 형태로 저장\n",
    "trials.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20427a",
   "metadata": {},
   "source": [
    "- hyperopt를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a260bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:18<00:00,  2.70trial/s, best loss: -0.971830985915493] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': np.float64(0.5626517105133655),\n",
       " 'learning_rate': np.float64(0.19986239480017942),\n",
       " 'max_depth': np.float64(4.0),\n",
       " 'n_estimators': np.float64(500.0)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# 1. 검색 공간 생성\n",
    "search_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 100),\n",
    "    'max_depth':hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate':hp.uniform('learning_rate', 0.01, 0.2),     # 0.01 ~ 0.2. q(간격) 지정x, 연속적인 실수값을 임의로 고름\n",
    "    'colsample_bytree':hp.uniform('colsample_bytree', 0.5, 1)\n",
    "    # tree 생성할 때 사용할 '특성'의 샘플링 비율 조정\n",
    "} # XGBoost에서 설정해줄 수 있는 하이퍼 파라미터 값을 저장\n",
    "\n",
    "# 2. 목적 함수 생성\n",
    "def xgb_objective(search_space):\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators = int(search_space['n_estimators']),\n",
    "        max_depth = int(search_space['max_depth']),\n",
    "        # 위 두 개 하이퍼 파라미터는 정수로만 받을 수 있음. 형변환 필요\n",
    "\n",
    "        learning_rate = search_space['learning_rate'],\n",
    "        colsample_bytree = search_space['colsample_bytree']\n",
    "        # 각 하이퍼 파라미터에 검색 공간 저장\n",
    "    )\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    return {\n",
    "        'loss': (-1) * mean_acc, # loss 함수 최솟값을 찾으므로 mean_acc 자체는 최댓값을 찾아야 함\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# 3. trials() + fmin()\n",
    "best = fmin(\n",
    "    fn=xgb_objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals = 50,\n",
    "    trials=trials\n",
    ")\n",
    "best\n",
    "# best loss: -0.971830985915493 -> 97점 정도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8966f5f",
   "metadata": {},
   "source": [
    "---\n",
    "##### Optuna\n",
    "\n",
    "trial 객체의 메서드에 의존해 수행함(샘플링함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6d5db",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>함수명</th>\n",
    "            <th>설명</th>\n",
    "            <th>사용 방법</th>\n",
    "            <th>예시 코드</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>suggest_uniform</td>\n",
    "            <td>연속적인 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_uniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_discrete_uniform</td>\n",
    "            <td>연속적이지만 일정 간격(step)을 갖는 값 샘플링</td>\n",
    "            <td>trial.suggest_discrete_uniform(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_discrete_uniform('num_layers', 1, 5, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_loguniform</td>\n",
    "            <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_loguniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_loguniform('reg_param', 1e-3, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_int</td>\n",
    "            <td>정수 값 샘플링</td>\n",
    "            <td>trial.suggest_int(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_int('num_trees', 1, 100)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_categorical</td>\n",
    "            <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "            <td>trial.suggest_categorical(name, choices)</td>\n",
    "            <td><code>trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_float</td>\n",
    "            <td>연속적인 실수 값 샘플링 (<code>step</code> 사용 가능)</td>\n",
    "            <td>trial.suggest_float(name, low, high, step=None, log=False)</td>\n",
    "            <td><code>trial.suggest_float('alpha', 0.1, 1.0, step=0.1)</code></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a51ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\ml_env\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------------- -------------------------- 2/6 [colorlog]\n",
      "   ------------- -------------------------- 2/6 [colorlog]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   ---------------------------------------- 6/6 [optuna]\n",
      "\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.5 colorlog-6.9.0 greenlet-3.2.4 optuna-4.5.0 sqlalchemy-2.0.43\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa9fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-25 16:06:06,112] A new study created in memory with name: no-name-8400c017-b239-469e-af11-11a17b710932\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\126773641.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  x=trial.suggest_uniform('x', -10, 10) # 'x'는 라벨명\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\126773641.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  y=trial.suggest_uniform('y', -15, 15)\n",
      "[I 2025-09-25 16:06:06,112] Trial 0 finished with value: 52.62668740461417 and parameters: {'x': 2.8196848780349537, 'y': -12.252184075256563}. Best is trial 0 with value: 52.62668740461417.\n",
      "[I 2025-09-25 16:06:06,112] Trial 1 finished with value: 7.379249330643109 and parameters: {'x': 3.4131306389045264, 'y': -7.684878471335611}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,117] Trial 2 finished with value: 49.25554566801907 and parameters: {'x': 4.110019216562534, 'y': 1.9298919909967545}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,120] Trial 3 finished with value: 89.76411280861431 and parameters: {'x': 8.656542684558815, 'y': -12.600502461441511}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,123] Trial 4 finished with value: 381.50009000247735 and parameters: {'x': 7.425512894929831, 'y': 14.024061753981119}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,126] Trial 5 finished with value: 73.4719429978145 and parameters: {'x': -4.443168301763172, 'y': -0.7489779311979046}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,130] Trial 6 finished with value: 76.60330997064975 and parameters: {'x': -2.898982126039744, 'y': -11.465703352869923}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,130] Trial 7 finished with value: 124.54808441859954 and parameters: {'x': -7.702334376190089, 'y': -1.8364381910859677}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,130] Trial 8 finished with value: 138.17259143784872 and parameters: {'x': 1.4913538509996567, 'y': 6.657468774779332}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,130] Trial 9 finished with value: 100.27713707230214 and parameters: {'x': -0.17426235147933333, 'y': -14.497430999816899}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,138] Trial 10 finished with value: 157.19342234322397 and parameters: {'x': -9.520891887297445, 'y': -5.648605187947952}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,142] Trial 11 finished with value: 109.77408333040839 and parameters: {'x': 5.047378514991459, 'y': 5.275326006835975}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,148] Trial 12 finished with value: 7.811969975779277 and parameters: {'x': 5.213306637362983, 'y': -6.706822692837262}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,153] Trial 13 finished with value: 13.912774689013645 and parameters: {'x': 6.3262247592580705, 'y': -6.687899149804939}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,161] Trial 14 finished with value: 47.86996851142551 and parameters: {'x': 9.594499614820007, 'y': -7.093452493266635}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,164] Trial 15 finished with value: 25.36131065505904 and parameters: {'x': -0.5892493982082199, 'y': -8.532506109339511}. Best is trial 1 with value: 7.379249330643109.\n",
      "[I 2025-09-25 16:06:06,166] Trial 16 finished with value: 2.4273183621822665 and parameters: {'x': 2.500571740954854, 'y': -3.5242324789285404}. Best is trial 16 with value: 2.4273183621822665.\n",
      "[I 2025-09-25 16:06:06,171] Trial 17 finished with value: 33.11971729173059 and parameters: {'x': -2.4393763417803953, 'y': -3.1203983655544696}. Best is trial 16 with value: 2.4273183621822665.\n",
      "[I 2025-09-25 16:06:06,174] Trial 18 finished with value: 68.57267597114445 and parameters: {'x': 1.7173731997900261, 'y': 3.1809256482703465}. Best is trial 16 with value: 2.4273183621822665.\n",
      "[I 2025-09-25 16:06:06,180] Trial 19 finished with value: 297.57618261345857 and parameters: {'x': -5.651316100772036, 'y': 9.924172082161915}. Best is trial 16 with value: 2.4273183621822665.\n",
      "[I 2025-09-25 16:06:06,186] Trial 20 finished with value: 1.974308471978774 and parameters: {'x': 2.998330300865191, 'y': -3.5949001159762437}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,193] Trial 21 finished with value: 2.56960378478389 and parameters: {'x': 3.3478817696440295, 'y': -3.435205425899863}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,197] Trial 22 finished with value: 4.059818839702864 and parameters: {'x': 1.2692940447346381, 'y': -3.968265665923696}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,204] Trial 23 finished with value: 61.56561775142973 and parameters: {'x': -1.4622615116946545, 'y': 1.4539786142098632}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,209] Trial 24 finished with value: 16.647401954782026 and parameters: {'x': 6.867576570347591, 'y': -3.7002871750727433}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,215] Trial 25 finished with value: 23.58391294042414 and parameters: {'x': 2.7818346923120285, 'y': -0.14857579272379473}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,221] Trial 26 finished with value: 27.268297713193967 and parameters: {'x': 0.6736296820344934, 'y': -9.675072069699358}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,228] Trial 27 finished with value: 3.1237248539823272 and parameters: {'x': 4.731930369934929, 'y': -4.647662026344893}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,231] Trial 28 finished with value: 7.061059782265072 and parameters: {'x': 2.705183764067424, 'y': -2.3591396914460585}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,237] Trial 29 finished with value: 79.20472363818763 and parameters: {'x': 6.021694331561632, 'y': 3.37102663983313}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,241] Trial 30 finished with value: 27.855033478102065 and parameters: {'x': 2.6601578444624674, 'y': -10.266834038340459}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,241] Trial 31 finished with value: 2.3650102179851573 and parameters: {'x': 4.532515977091682, 'y': -5.128081996954622}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,241] Trial 32 finished with value: 14.719889602199208 and parameters: {'x': 3.671394226929932, 'y': -1.2225512056092187}. Best is trial 20 with value: 1.974308471978774.\n",
      "[I 2025-09-25 16:06:06,241] Trial 33 finished with value: 1.3506057350318232 and parameters: {'x': 4.150791310952776, 'y': -4.837873217303822}. Best is trial 33 with value: 1.3506057350318232.\n",
      "[I 2025-09-25 16:06:06,254] Trial 34 finished with value: 20.86738074599292 and parameters: {'x': 7.530671852416988, 'y': -5.583432354013157}. Best is trial 33 with value: 1.3506057350318232.\n",
      "[I 2025-09-25 16:06:06,256] Trial 35 finished with value: 34.641194818430904 and parameters: {'x': 4.426919229128174, 'y': 0.7100872438146829}. Best is trial 33 with value: 1.3506057350318232.\n",
      "[I 2025-09-25 16:06:06,256] Trial 36 finished with value: 38.74421508277979 and parameters: {'x': 8.23097849415698, 'y': -8.373585492683853}. Best is trial 33 with value: 1.3506057350318232.\n",
      "[I 2025-09-25 16:06:06,256] Trial 37 finished with value: 1.017678493558336 and parameters: {'x': 1.9916886189444283, 'y': -5.031411023417612}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,256] Trial 38 finished with value: 39.77970629648366 and parameters: {'x': 5.757822240260023, 'y': -10.672223795621154}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,256] Trial 39 finished with value: 64.72528363371416 and parameters: {'x': 3.9973874119971855, 'y': -12.983138604841063}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,272] Trial 40 finished with value: 19.315435479881792 and parameters: {'x': 0.3277271512831583, 'y': -8.489182325687864}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,272] Trial 41 finished with value: 1.1616766932507034 and parameters: {'x': 1.9773501589311295, 'y': -5.340388007738988}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,272] Trial 42 finished with value: 2.446820083128908 and parameters: {'x': 1.4873190337335527, 'y': -5.398266716440271}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,272] Trial 43 finished with value: 15.590615095240894 and parameters: {'x': 3.7858250136380818, 'y': -1.1304917440091171}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,272] Trial 44 finished with value: 26.585793904205833 and parameters: {'x': -1.3115741900243276, 'y': -2.1722585146230395}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,290] Trial 45 finished with value: 2.052892451873734 and parameters: {'x': 2.036868583502255, 'y': -6.060787597226128}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,290] Trial 46 finished with value: 3.7070360209024913 and parameters: {'x': 2.0834520759884247, 'y': -6.693214671532397}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,290] Trial 47 finished with value: 363.4576302338131 and parameters: {'x': 0.654533457977998, 'y': 13.919736175065141}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,290] Trial 48 finished with value: 61.14417630126178 and parameters: {'x': -3.4610657719208113, 'y': -9.404407496153723}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,290] Trial 49 finished with value: 16.638670358753043 and parameters: {'x': -0.3494972175379689, 'y': -7.327990281006011}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,306] Trial 50 finished with value: 55.29017652178108 and parameters: {'x': 1.1300607055230643, 'y': -12.196770355982757}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,309] Trial 51 finished with value: 4.802574656519962 and parameters: {'x': 5.1913338596914915, 'y': -5.025111190524397}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,309] Trial 52 finished with value: 2.026268415920314 and parameters: {'x': 1.9971160190893522, 'y': -6.010194108452987}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,309] Trial 53 finished with value: 1.2655202056087065 and parameters: {'x': 3.4076552870706456, 'y': -6.048492905332247}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,309] Trial 54 finished with value: 9.599031227702945 and parameters: {'x': 3.151972579464954, 'y': -8.094500858425105}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,322] Trial 55 finished with value: 6.684987610418615 and parameters: {'x': 3.577825266099647, 'y': -2.4798600093892627}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,323] Trial 56 finished with value: 19.022574447185185 and parameters: {'x': -1.1103015957893996, 'y': -6.458764970389781}. Best is trial 37 with value: 1.017678493558336.\n",
      "[I 2025-09-25 16:06:06,323] Trial 57 finished with value: 0.7122529236774834 and parameters: {'x': 2.2774295719996798, 'y': -4.563943925329646}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,323] Trial 58 finished with value: 7.259267346189489 and parameters: {'x': 5.559367386760014, 'y': -4.158034486585879}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,323] Trial 59 finished with value: 27.015161309302815 and parameters: {'x': 0.07173561606229839, 'y': -0.7057679374462338}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,340] Trial 60 finished with value: 16.404011492713973 and parameters: {'x': 6.979379457113448, 'y': -4.245977036810249}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,341] Trial 61 finished with value: 6.792962720028546 and parameters: {'x': 2.119893373061588, 'y': -7.453237665870887}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,341] Trial 62 finished with value: 4.15303996690829 and parameters: {'x': 3.119656008333923, 'y': -2.965614980742858}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,341] Trial 63 finished with value: 4.331561281831778 and parameters: {'x': 1.318177324387192, 'y': -6.225982777051274}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,341] Trial 64 finished with value: 1.7733026458394143 and parameters: {'x': 4.281422144833194, 'y': -4.6377018733549535}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,356] Trial 65 finished with value: 12.042609561738493 and parameters: {'x': 4.17777772019843, 'y': -1.7357314443289624}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,365] Trial 66 finished with value: 30.47552742553698 and parameters: {'x': 4.954977215155488, 'y': 0.16271164348347789}. Best is trial 57 with value: 0.7122529236774834.\n",
      "[I 2025-09-25 16:06:06,372] Trial 67 finished with value: 0.3607815821029822 and parameters: {'x': 2.539782565534792, 'y': -4.614018789165529}. Best is trial 67 with value: 0.3607815821029822.\n",
      "[I 2025-09-25 16:06:06,374] Trial 68 finished with value: 4.727028270709517 and parameters: {'x': 0.8262094738231132, 'y': -5.040780130126456}. Best is trial 67 with value: 0.3607815821029822.\n",
      "[I 2025-09-25 16:06:06,383] Trial 69 finished with value: 17.506859632375257 and parameters: {'x': 2.6283389226730405, 'y': -9.167580554227527}. Best is trial 67 with value: 0.3607815821029822.\n",
      "[I 2025-09-25 16:06:06,390] Trial 70 finished with value: 15.143435204089522 and parameters: {'x': 6.613274172781635, 'y': -3.555117666936607}. Best is trial 67 with value: 0.3607815821029822.\n",
      "[I 2025-09-25 16:06:06,391] Trial 71 finished with value: 0.16793856063344498 and parameters: {'x': 3.2956306422199453, 'y': -4.716202388991613}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,391] Trial 72 finished with value: 1.3554403597070563 and parameters: {'x': 4.095958747642881, 'y': -4.607170796436793}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,408] Trial 73 finished with value: 5.199151062933531 and parameters: {'x': 3.3229216210830685, 'y': -7.257182467052811}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,408] Trial 74 finished with value: 5.600171309256986 and parameters: {'x': 2.366673943985612, 'y': -2.71985320296472}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,408] Trial 75 finished with value: 102.19097294768069 and parameters: {'x': -7.081314608178776, 'y': -4.252960028778972}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,408] Trial 76 finished with value: 2.5485679058691333 and parameters: {'x': 1.5139864840581752, 'y': -5.583379581668187}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,421] Trial 77 finished with value: 3.750894310809988 and parameters: {'x': 3.777792120484336, 'y': -3.226321977324388}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,424] Trial 78 finished with value: 11.168537303766934 and parameters: {'x': 4.6995102364922, 'y': -7.877534058847116}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,427] Trial 79 finished with value: 19.288345553485076 and parameters: {'x': 5.930731965706722, 'y': -1.729043611010705}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,427] Trial 80 finished with value: 35.4629337696136 and parameters: {'x': 2.9032762356672093, 'y': -10.954290745590686}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,427] Trial 81 finished with value: 1.6820765215666906 and parameters: {'x': 4.296319060426284, 'y': -5.040415530952926}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,439] Trial 82 finished with value: 8.493951267149594 and parameters: {'x': 5.327282254720059, 'y': -6.754339925446239}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,441] Trial 83 finished with value: 1.3946859642467406 and parameters: {'x': 4.170027479691257, 'y': -4.839620259963839}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,441] Trial 84 finished with value: 0.8112655921594513 and parameters: {'x': 3.56411740642623, 'y': -5.702166037292032}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,441] Trial 85 finished with value: 2.134267418573301 and parameters: {'x': 1.843989105883781, 'y': -5.893255971856847}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,453] Trial 86 finished with value: 15.658525917131206 and parameters: {'x': 3.4263356684531465, 'y': -8.93405183175512}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,456] Trial 87 finished with value: 185.60777471576193 and parameters: {'x': -9.665083594121866, 'y': -10.020302009806493}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,456] Trial 88 finished with value: 1.478245543127559 and parameters: {'x': 2.5210814599898215, 'y': -3.8824658505611214}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,456] Trial 89 finished with value: 7.632329786213663 and parameters: {'x': 0.9589250592708496, 'y': -6.861811717801013}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,456] Trial 90 finished with value: 56.45906213043369 and parameters: {'x': -0.5883575532367757, 'y': 1.6017234265426687}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,472] Trial 91 finished with value: 0.831872814040295 and parameters: {'x': 3.906800691588242, 'y': -4.902095353657851}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,475] Trial 92 finished with value: 0.9875560416091038 and parameters: {'x': 3.7227814243346407, 'y': -5.6820139692454195}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,475] Trial 93 finished with value: 7.584047766976003 and parameters: {'x': 2.960319234131573, 'y': -7.753629096991114}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,475] Trial 94 finished with value: 172.17342529101037 and parameters: {'x': 0.2961015942694665, 'y': 7.839873780629552}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,475] Trial 95 finished with value: 1.0412968842958907 and parameters: {'x': 3.62341007318246, 'y': -5.807871750310983}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,488] Trial 96 finished with value: 2.0220769493327886 and parameters: {'x': 2.3008488694088203, 'y': -6.238250639380357}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,489] Trial 97 finished with value: 0.7680601200373436 and parameters: {'x': 3.670673126265607, 'y': -5.564143313123944}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,489] Trial 98 finished with value: 2.2397591383200024 and parameters: {'x': 1.5982105819609336, 'y': -5.524161774449166}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,498] Trial 99 finished with value: 5.922793301730854 and parameters: {'x': 4.609273624237895, 'y': -3.1743407480958874}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,503] Trial 100 finished with value: 4.578915765037818 and parameters: {'x': 4.862368876680354, 'y': -3.946198343040696}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,506] Trial 101 finished with value: 0.6086732010890701 and parameters: {'x': 3.4229728069156944, 'y': -5.655566324408849}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,506] Trial 102 finished with value: 4.656323330553556 and parameters: {'x': 3.119388049375444, 'y': -7.154546315171684}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,506] Trial 103 finished with value: 9.953496224764239 and parameters: {'x': 3.5366461853359787, 'y': -8.10893986698498}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,506] Trial 104 finished with value: 0.930419448068964 and parameters: {'x': 3.823126666671479, 'y': -5.502873680642827}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,520] Trial 105 finished with value: 12.92003535251775 and parameters: {'x': 5.3172237434010485, 'y': -2.2521809601911222}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,524] Trial 106 finished with value: 14.500584433443281 and parameters: {'x': 3.808743935952334, 'y': -8.721090925992485}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,524] Trial 107 finished with value: 0.5279270799158655 and parameters: {'x': 2.5080419791203705, 'y': -4.465299723575849}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,524] Trial 108 finished with value: 0.3266352551528498 and parameters: {'x': 2.6505223113319936, 'y': -4.54778257411272}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,524] Trial 109 finished with value: 0.541290183904662 and parameters: {'x': 2.654715050760185, 'y': -4.350332017309518}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,540] Trial 110 finished with value: 2.1633986320897898 and parameters: {'x': 2.6219910738607757, 'y': -3.5785542979596934}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,540] Trial 111 finished with value: 0.7298899734531056 and parameters: {'x': 2.8998941042545785, 'y': -4.151549186404944}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,540] Trial 112 finished with value: 0.4023902542331037 and parameters: {'x': 2.9192631575980945, 'y': -4.3708165478081344}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,540] Trial 113 finished with value: 0.29884855700629126 and parameters: {'x': 2.8062958328144894, 'y': -4.488798227094957}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,554] Trial 114 finished with value: 0.6661304245085451 and parameters: {'x': 2.879050111530286, 'y': -4.192843541196808}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,558] Trial 115 finished with value: 5.369988826970671 and parameters: {'x': 2.3316210025761266, 'y': -2.781158333099604}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,558] Trial 116 finished with value: 13.50744869213913 and parameters: {'x': 2.871641375628909, 'y': -1.3269940436083294}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,558] Trial 117 finished with value: 2.566776525237677 and parameters: {'x': 1.6580159048979661, 'y': -4.124868459184077}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,558] Trial 118 finished with value: 22.532967351308283 and parameters: {'x': 2.630902884814143, 'y': -0.26748114944380186}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,572] Trial 119 finished with value: 6.917934941357558 and parameters: {'x': 1.066495034990989, 'y': -3.2168865735340724}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,572] Trial 120 finished with value: 0.29972417426136133 and parameters: {'x': 3.128685514421256, 'y': -4.4678682375205385}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,572] Trial 121 finished with value: 0.27136814498369766 and parameters: {'x': 3.0453526114511207, 'y': -4.4810478966048395}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,572] Trial 122 finished with value: 0.4081337732124141 and parameters: {'x': 3.0851785634055506, 'y': -4.366850424031903}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,572] Trial 123 finished with value: 0.8394933883054085 and parameters: {'x': 2.1442868794390586, 'y': -4.6725119183767685}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,589] Trial 124 finished with value: 10.209431383184903 and parameters: {'x': 3.2574987284241343, 'y': -1.8151725654213449}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,589] Trial 125 finished with value: 7.222398151295955 and parameters: {'x': 1.7727713509167073, 'y': -2.6091198285641433}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,589] Trial 126 finished with value: 7.54440351309321 and parameters: {'x': 0.6295328713243304, 'y': -3.6124521251642037}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,589] Trial 127 finished with value: 0.5894400309673653 and parameters: {'x': 2.38035289374988, 'y': -4.546703745125533}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,603] Trial 128 finished with value: 5.48391180735442 and parameters: {'x': 1.2273695814752934, 'y': -6.530259195912687}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,608] Trial 129 finished with value: 0.28074797760425596 and parameters: {'x': 3.244516631964448, 'y': -4.529936606086989}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,608] Trial 130 finished with value: 3.1678201158998873 and parameters: {'x': 3.163631718397079, 'y': -3.2277007090690617}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,608] Trial 131 finished with value: 0.7353961841325998 and parameters: {'x': 2.520897388900754, 'y': -4.28876384219411}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,608] Trial 132 finished with value: 0.19196283023712912 and parameters: {'x': 2.8206969349692907, 'y': -4.600233516777954}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,623] Trial 133 finished with value: 2.11441239475982 and parameters: {'x': 4.441731825053037, 'y': -4.810733681313716}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,630] Trial 134 finished with value: 59.558862551467804 and parameters: {'x': 1.9601715357544476, 'y': 2.6470660593728716}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,639] Trial 135 finished with value: 5.645025194713784 and parameters: {'x': 3.1353721062623485, 'y': -2.627933477416816}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,644] Trial 136 finished with value: 2.4608375441638946 and parameters: {'x': 2.404856395977487, 'y': -6.451427447292833}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,658] Trial 137 finished with value: 4.416525710402219 and parameters: {'x': 1.4703015196497435, 'y': -3.5589766588926}. Best is trial 71 with value: 0.16793856063344498.\n",
      "[I 2025-09-25 16:06:06,662] Trial 138 finished with value: 0.07180734190285593 and parameters: {'x': 2.778721767922697, 'y': -5.151139954716148}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,672] Trial 139 finished with value: 0.10854592709155812 and parameters: {'x': 2.7500789868347524, 'y': -5.214675136590184}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,676] Trial 140 finished with value: 44.019261169214815 and parameters: {'x': 9.634409842741462, 'y': -5.062186877635216}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,678] Trial 141 finished with value: 0.5709146525311541 and parameters: {'x': 2.63810034362307, 'y': -4.3367177891384285}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,678] Trial 142 finished with value: 1.6654722412980592 and parameters: {'x': 2.7897658282985773, 'y': -3.7267074828040982}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,689] Trial 143 finished with value: 1.105772336257482 and parameters: {'x': 1.9617137078503633, 'y': -5.1665350167131265}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,693] Trial 144 finished with value: 9.891199512095561 and parameters: {'x': 4.11065730163592, 'y': -2.057613235752584}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,696] Trial 145 finished with value: 0.20269698006311104 and parameters: {'x': 2.9962913473630963, 'y': -4.549796461632375}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,696] Trial 146 finished with value: 1.4820885652740454 and parameters: {'x': 3.21610759964364, 'y': -6.198075987010135}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,704] Trial 147 finished with value: 4.438734655441683 and parameters: {'x': 3.3038790356865646, 'y': -2.915199724886845}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,707] Trial 148 finished with value: 4.591770467680805 and parameters: {'x': 2.126039847374045, 'y': -6.956518366717477}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,709] Trial 149 finished with value: 1.7279621691134677 and parameters: {'x': 2.927189156776491, 'y': -3.6874982856306247}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,709] Trial 150 finished with value: 88.25028270372893 and parameters: {'x': 4.106510978745494, 'y': -14.32876820151753}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,719] Trial 151 finished with value: 0.6439708169096441 and parameters: {'x': 2.4416688689256985, 'y': -4.423599822186933}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,725] Trial 152 finished with value: 0.1802398896384514 and parameters: {'x': 2.6251778281486167, 'y': -5.199369579241828}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,726] Trial 153 finished with value: 2.178331785483067 and parameters: {'x': 1.5398024407348483, 'y': -5.214836852981887}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,726] Trial 154 finished with value: 1.2642706007831406 and parameters: {'x': 3.4388709919063847, 'y': -6.035211501697236}. Best is trial 138 with value: 0.07180734190285593.\n",
      "[I 2025-09-25 16:06:06,737] Trial 155 finished with value: 0.06689799444172187 and parameters: {'x': 2.83717244411899, 'y': -5.200960646614053}. Best is trial 155 with value: 0.06689799444172187.\n",
      "[I 2025-09-25 16:06:06,740] Trial 156 finished with value: 0.03639580898820557 and parameters: {'x': 2.951956491442431, 'y': -5.184628357176476}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,743] Trial 157 finished with value: 0.7983916160412199 and parameters: {'x': 3.892116616604489, 'y': -4.94980479684891}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,743] Trial 158 finished with value: 310.1677967715079 and parameters: {'x': 2.99515105650207, 'y': 12.611580657602966}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,752] Trial 159 finished with value: 8.435449250036948 and parameters: {'x': 4.592546673765337, 'y': -7.428836005562316}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,756] Trial 160 finished with value: 1.5284882522499221 and parameters: {'x': 1.8176561490713947, 'y': -5.361318793340781}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,759] Trial 161 finished with value: 1.680239070887018 and parameters: {'x': 3.5119240072710873, 'y': -3.8091293598100044}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,759] Trial 162 finished with value: 0.7846398014483101 and parameters: {'x': 2.8551298838187904, 'y': -5.873872102132774}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,770] Trial 163 finished with value: 3.0986202640112683 and parameters: {'x': 2.2024465399048045, 'y': -6.569244640679537}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,774] Trial 164 finished with value: 30.111316430468914 and parameters: {'x': -2.476008715748724, 'y': -4.646949046860202}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,777] Trial 165 finished with value: 3.022236351174908 and parameters: {'x': 3.1679797468846864, 'y': -3.269676574795491}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,782] Trial 166 finished with value: 0.23195992412493602 and parameters: {'x': 2.595194521110895, 'y': -5.26094529768957}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,787] Trial 167 finished with value: 0.6343901732237958 and parameters: {'x': 3.7329427912680524, 'y': -5.31174514904324}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,790] Trial 168 finished with value: 130.72950368889758 and parameters: {'x': -8.380325386259779, 'y': -6.103493448892558}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,795] Trial 169 finished with value: 1.2626271986839894 and parameters: {'x': 2.7991655459872384, 'y': -3.8944265195088184}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,795] Trial 170 finished with value: 108.41014497088871 and parameters: {'x': 2.17871024102526, 'y': 5.3795774529935425}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,802] Trial 171 finished with value: 0.26426145530496503 and parameters: {'x': 2.4863016979798425, 'y': -5.01937807540939}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,809] Trial 172 finished with value: 0.23955806136683322 and parameters: {'x': 3.322440162021063, 'y': -5.368226022006408}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,809] Trial 173 finished with value: 0.38283416667750786 and parameters: {'x': 3.592516529193707, 'y': -5.178208667886135}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,809] Trial 174 finished with value: 65.0080811077372 and parameters: {'x': -5.054032161230411, 'y': -5.375029403651796}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,822] Trial 175 finished with value: 3.600122586446278 and parameters: {'x': 3.502287943088893, 'y': -6.8297074653271235}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,827] Trial 176 finished with value: 1.670406213959178 and parameters: {'x': 3.983625589566547, 'y': -5.838383512188211}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,831] Trial 177 finished with value: 0.37415696468665954 and parameters: {'x': 2.416214781871233, 'y': -5.182624707476857}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,835] Trial 178 finished with value: 3.4041777291129875 and parameters: {'x': 1.7942698326850455, 'y': -6.39656453225035}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,840] Trial 179 finished with value: 0.3628906915118921 and parameters: {'x': 2.4228825315206466, 'y': -4.827297599646459}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,840] Trial 180 finished with value: 3.2943073788487527 and parameters: {'x': 1.1879373310480112, 'y': -4.896384061846898}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,840] Trial 181 finished with value: 0.528077188755277 and parameters: {'x': 2.48082760932631, 'y': -5.508465551947664}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,840] Trial 182 finished with value: 0.8091957597495415 and parameters: {'x': 2.134459304704241, 'y': -4.754979460990562}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,856] Trial 183 finished with value: 0.9925600330476423 and parameters: {'x': 2.51784192310177, 'y': -5.871827747854725}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,856] Trial 184 finished with value: 1.2013095132561924 and parameters: {'x': 3.0233349800424363, 'y': -3.904205771158375}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,863] Trial 185 finished with value: 0.08547034751092988 and parameters: {'x': 2.707700368121495, 'y': -5.005592201232108}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,863] Trial 186 finished with value: 2.555498678302449 and parameters: {'x': 3.2263693683729944, 'y': -3.4175160072326607}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,871] Trial 187 finished with value: 0.1482957899773881 and parameters: {'x': 2.6899802390085807, 'y': -4.771562836271741}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,883] Trial 188 finished with value: 0.7878045364589904 and parameters: {'x': 2.880436516725787, 'y': -4.1205063332085174}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,894] Trial 189 finished with value: 3.1195742869366545 and parameters: {'x': 1.8049102848131284, 'y': -6.300513306195372}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,905] Trial 190 finished with value: 4.165749946455089 and parameters: {'x': 3.4612103370995815, 'y': -3.0117759252519902}. Best is trial 156 with value: 0.03639580898820557.\n",
      "[I 2025-09-25 16:06:06,916] Trial 191 finished with value: 0.029504690643549762 and parameters: {'x': 2.832150132709489, 'y': -5.036484417140851}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,929] Trial 192 finished with value: 0.19500759974470513 and parameters: {'x': 2.6944884785896, 'y': -4.681142178972809}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,940] Trial 193 finished with value: 0.3669755195476567 and parameters: {'x': 3.2717762076367696, 'y': -5.54139930966915}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,944] Trial 194 finished with value: 0.10951892382978047 and parameters: {'x': 2.937477890189868, 'y': -4.675023216806692}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,949] Trial 195 finished with value: 1.8528767658917191 and parameters: {'x': 3.892899629801663, 'y': -3.972572622035128}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,952] Trial 196 finished with value: 0.03582135472576679 and parameters: {'x': 2.8467686709518083, 'y': -5.1110923693324235}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,956] Trial 197 finished with value: 3.7831069551978085 and parameters: {'x': 2.7892344226746997, 'y': -6.933567900698742}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,956] Trial 198 finished with value: 1.4427518148929004 and parameters: {'x': 2.128333127258313, 'y': -5.826407089670477}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,956] Trial 199 finished with value: 1.8641528908865728 and parameters: {'x': 4.340904959759205, 'y': -5.25715127800526}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,971] Trial 200 finished with value: 0.17538505677139718 and parameters: {'x': 3.401877760673903, 'y': -4.8821894646174355}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,975] Trial 201 finished with value: 0.1584851059956493 and parameters: {'x': 3.347224386446567, 'y': -4.805268565833725}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,975] Trial 202 finished with value: 0.2504133644703419 and parameters: {'x': 3.443252322778817, 'y': -4.767748535372702}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,980] Trial 203 finished with value: 0.41090724215437774 and parameters: {'x': 3.611113546919732, 'y': -5.1935135006286695}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,987] Trial 204 finished with value: 1.5873839863540422 and parameters: {'x': 3.3961458190915446, 'y': -6.196015249221485}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,991] Trial 205 finished with value: 0.0454237434731593 and parameters: {'x': 2.790301532409259, 'y': -4.961917245855188}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,991] Trial 206 finished with value: 0.8147832073950345 and parameters: {'x': 2.7456193294101454, 'y': -5.866067942961342}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:06,996] Trial 207 finished with value: 1.3565371371094088 and parameters: {'x': 4.1627335916949635, 'y': -5.06773279747315}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,005] Trial 208 finished with value: 0.9564063148702708 and parameters: {'x': 3.8136233263402506, 'y': -5.542607959493129}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,007] Trial 209 finished with value: 2.2543871536936635 and parameters: {'x': 2.2676603731839338, 'y': -3.6892498999852914}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,007] Trial 210 finished with value: 2.3327002494774387 and parameters: {'x': 2.7114140083643203, 'y': -6.499806112438901}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,007] Trial 211 finished with value: 0.09343360262132915 and parameters: {'x': 3.136866621696229, 'y': -4.7266849245160625}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,021] Trial 212 finished with value: 0.05581696820148409 and parameters: {'x': 3.2137435934523824, 'y': -4.899348897375405}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,022] Trial 213 finished with value: 0.11310604648327155 and parameters: {'x': 3.258482162358761, 'y': -4.784841876226784}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,022] Trial 214 finished with value: 0.3982442656589895 and parameters: {'x': 3.092412843476881, 'y': -5.624262870928191}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,037] Trial 215 finished with value: 0.8500063072511539 and parameters: {'x': 2.954619052515034, 'y': -4.079159689817762}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,039] Trial 216 finished with value: 0.5417489633255178 and parameters: {'x': 3.7230377202800016, 'y': -4.862285010337233}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,039] Trial 217 finished with value: 0.874673459574546 and parameters: {'x': 3.145021215661262, 'y': -4.076072347755153}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,039] Trial 218 finished with value: 1.3150570062801374 and parameters: {'x': 3.4808146427565703, 'y': -6.041092832359828}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,053] Trial 219 finished with value: 1.151345018704742 and parameters: {'x': 1.9276452349520559, 'y': -4.9625797303094865}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,057] Trial 220 finished with value: 0.3514976543009164 and parameters: {'x': 2.730747809287097, 'y': -5.52820536924308}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,061] Trial 221 finished with value: 0.19794348887472268 and parameters: {'x': 3.2854577271414542, 'y': -4.658741483783983}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,061] Trial 222 finished with value: 0.32553446053712287 and parameters: {'x': 3.218765281510364, 'y': -4.473050085736022}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,071] Trial 223 finished with value: 1.2081460786709233 and parameters: {'x': 4.051278373188099, 'y': -5.3208735899663715}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,075] Trial 224 finished with value: 2.0735095587049526 and parameters: {'x': 2.6614965197812004, 'y': -3.600383998167814}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,075] Trial 225 finished with value: 0.5438106513629569 and parameters: {'x': 2.30422876535766, 'y': -4.755637481582729}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,075] Trial 226 finished with value: 0.694167683954842 and parameters: {'x': 3.2843871325819833, 'y': -4.216870609173274}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,088] Trial 227 finished with value: 1.022690110162614 and parameters: {'x': 2.890954425831242, 'y': -6.005385086878068}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,094] Trial 228 finished with value: 0.537003685619911 and parameters: {'x': 3.7041408389084993, 'y': -5.202951631186216}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,098] Trial 229 finished with value: 0.3633920516612743 and parameters: {'x': 2.5265899820848134, 'y': -4.6268043320202965}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,101] Trial 230 finished with value: 3.0587191826247504 and parameters: {'x': 3.0482611097404897, 'y': -6.748253427827718}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,107] Trial 231 finished with value: 0.20657130455817077 and parameters: {'x': 3.439243197014322, 'y': -4.883223639229473}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,111] Trial 232 finished with value: 0.35887581953181735 and parameters: {'x': 3.4187400474793144, 'y': -5.428407040288601}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,115] Trial 233 finished with value: 1.620203727299678 and parameters: {'x': 3.861490073391194, 'y': -4.062962871200872}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,120] Trial 234 finished with value: 0.03403804510078524 and parameters: {'x': 2.922439642690933, 'y': -4.83260096752109}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,122] Trial 235 finished with value: 2.8062073515369166 and parameters: {'x': 2.7935601158479986, 'y': -3.337595137829468}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,122] Trial 236 finished with value: 0.8655966652218622 and parameters: {'x': 2.1521278259872836, 'y': -4.616973314563055}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,122] Trial 237 finished with value: 0.9676992772395803 and parameters: {'x': 3.0001160779627027, 'y': -4.016282935105075}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,136] Trial 238 finished with value: 0.1799375777801961 and parameters: {'x': 2.5771946335990243, 'y': -4.96574799388747}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,147] Trial 239 finished with value: 0.39832461808901387 and parameters: {'x': 3.590608553112703, 'y': -4.777500213305421}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,159] Trial 240 finished with value: 26.330263199460923 and parameters: {'x': 8.061319419679068, 'y': -5.844576184509408}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,164] Trial 241 finished with value: 0.31643138368038204 and parameters: {'x': 2.437775483797183, 'y': -4.981697621441725}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,174] Trial 242 finished with value: 0.47001705592421616 and parameters: {'x': 2.7277325572459112, 'y': -4.370804088108986}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,174] Trial 243 finished with value: 0.17268889999426468 and parameters: {'x': 3.072217440071202, 'y': -5.409235312923784}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,187] Trial 244 finished with value: 0.471133841271278 and parameters: {'x': 3.2162336786731993, 'y': -5.65144212135748}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,190] Trial 245 finished with value: 0.037779958260075124 and parameters: {'x': 3.079560491989149, 'y': -4.822658277964491}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,190] Trial 246 finished with value: 0.9758970093356409 and parameters: {'x': 2.9295447112312187, 'y': -4.01464064340965}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,190] Trial 247 finished with value: 2.0316648346609667 and parameters: {'x': 2.1475665035518956, 'y': -6.142375581319133}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,204] Trial 248 finished with value: 0.09493715982729685 and parameters: {'x': 3.0350454416154293, 'y': -4.693880780006749}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,209] Trial 249 finished with value: 2.4167995127091086 and parameters: {'x': 2.5471797469965525, 'y': -3.5128035330935585}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,212] Trial 250 finished with value: 0.08072757722477697 and parameters: {'x': 3.1559520377926824, 'y': -5.237500608700455}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,212] Trial 251 finished with value: 1.7614504032589953 and parameters: {'x': 1.7785974793588843, 'y': -5.519255511121957}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,221] Trial 252 finished with value: 1.5842982755501327 and parameters: {'x': 2.875526504463679, 'y': -6.25251931101245}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,222] Trial 253 finished with value: 0.6708064889590847 and parameters: {'x': 3.8182047382098845, 'y': -5.036708246076039}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,222] Trial 254 finished with value: 0.7724169255341783 and parameters: {'x': 2.326332955825368, 'y': -5.56443745368924}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,232] Trial 255 finished with value: 44.17836063889536 and parameters: {'x': -3.6130295727178563, 'y': -4.332017583124787}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,239] Trial 256 finished with value: 1.7780803288093132 and parameters: {'x': 4.330784950744977, 'y': -5.084212491234978}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,239] Trial 257 finished with value: 1.6836938577140672 and parameters: {'x': 3.142243512484302, 'y': -3.710247837423718}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,239] Trial 258 finished with value: 1.9333979587965606 and parameters: {'x': 2.656679358384803, 'y': -6.347415635888752}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,254] Trial 259 finished with value: 1.039009610693995 and parameters: {'x': 2.1602802024284156, 'y': -5.5778237380554145}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,256] Trial 260 finished with value: 0.7659519947232067 and parameters: {'x': 3.463809253359338, 'y': -4.25781877467733}. Best is trial 191 with value: 0.029504690643549762.\n",
      "[I 2025-09-25 16:06:07,263] Trial 261 finished with value: 0.0045083209950914725 and parameters: {'x': 2.99235703569182, 'y': -4.933292383555734}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,266] Trial 262 finished with value: 6.032861118431808 and parameters: {'x': 3.8421999116913965, 'y': -7.307284210317145}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,272] Trial 263 finished with value: 0.7822373393274593 and parameters: {'x': 3.1054588052536913, 'y': -5.87813198308792}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,276] Trial 264 finished with value: 0.34572836535841267 and parameters: {'x': 3.5701436061888256, 'y': -5.143751986700755}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,280] Trial 265 finished with value: 4.269458985629617 and parameters: {'x': 3.1073724282058746, 'y': -2.9365247403250043}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,284] Trial 266 finished with value: 0.35314706030870374 and parameters: {'x': 2.4080292774170178, 'y': -5.05213179368951}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,289] Trial 267 finished with value: 2.487419353270995 and parameters: {'x': 2.888636369891172, 'y': -6.573218832572246}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,289] Trial 268 finished with value: 1.989455851615911 and parameters: {'x': 4.038442630362466, 'y': -4.045488211145722}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,289] Trial 269 finished with value: 2.724642241612057 and parameters: {'x': 1.5746917365414528, 'y': -5.832549455425224}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,303] Trial 270 finished with value: 0.5341355447797183 and parameters: {'x': 3.586141615973559, 'y': -4.563452693510058}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,306] Trial 271 finished with value: 0.21947962465755005 and parameters: {'x': 2.6385983968232427, 'y': -5.298108211693036}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,313] Trial 272 finished with value: 1.215265274170585 and parameters: {'x': 3.2567740239102543, 'y': -3.9279307975622464}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,313] Trial 273 finished with value: 0.960042620623405 and parameters: {'x': 2.0683631593216423, 'y': -4.696527731556484}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,321] Trial 274 finished with value: 5.696556822076694 and parameters: {'x': 4.752026818295876, 'y': -3.379210423883247}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,324] Trial 275 finished with value: 0.7622571472442542 and parameters: {'x': 2.9181839221279278, 'y': -5.8692314287034755}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,330] Trial 276 finished with value: 0.5025489725230268 and parameters: {'x': 2.3376680644068193, 'y': -5.252716005857202}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,330] Trial 277 finished with value: 3.344374717976403 and parameters: {'x': 3.39248864416376, 'y': -6.786148757012947}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,339] Trial 278 finished with value: 0.3069509321123947 and parameters: {'x': 2.789216487040782, 'y': -4.487631731293822}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,339] Trial 279 finished with value: 1.6187028722390862 and parameters: {'x': 4.272256952876346, 'y': -5.0080695784822105}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,339] Trial 280 finished with value: 1.8598009310810586 and parameters: {'x': 3.7339699832695006, 'y': -6.14938635573093}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,353] Trial 281 finished with value: 2.3434879961613957 and parameters: {'x': 1.8815365968766096, 'y': -3.954759543437473}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,357] Trial 282 finished with value: 0.3411877591029418 and parameters: {'x': 3.3107392431709437, 'y': -5.494599718819664}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,357] Trial 283 finished with value: 0.31003143536871114 and parameters: {'x': 2.671808397464385, 'y': -4.550198146520253}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,357] Trial 284 finished with value: 38.95092200809324 and parameters: {'x': 9.032196324842879, 'y': -3.3988974090816977}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,372] Trial 285 finished with value: 0.34576049219748856 and parameters: {'x': 3.067921795844576, 'y': -5.584078010069491}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,389] Trial 286 finished with value: 0.30321371383516593 and parameters: {'x': 2.4528369657747677, 'y': -4.938142681818533}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,403] Trial 287 finished with value: 1.2501934791104963 and parameters: {'x': 3.9036973021665076, 'y': -4.341574100473355}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,413] Trial 288 finished with value: 2.0308115965588858 and parameters: {'x': 3.1345534006402467, 'y': -6.418699044524606}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,423] Trial 289 finished with value: 0.708613491326668 and parameters: {'x': 2.1632530317093965, 'y': -5.092021749511471}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,428] Trial 290 finished with value: 0.8327305382429193 and parameters: {'x': 2.7307935905583967, 'y': -5.871928005834472}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,439] Trial 291 finished with value: 69.00202458873255 and parameters: {'x': -1.5710483411548952, 'y': -11.935960038203625}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,442] Trial 292 finished with value: 1.7017560334253676 and parameters: {'x': 3.583985186556595, 'y': -3.8335021065994903}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,454] Trial 293 finished with value: 0.29018328048974024 and parameters: {'x': 3.026230782760884, 'y': -4.461952393811206}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,462] Trial 294 finished with value: 0.462605540254012 and parameters: {'x': 2.447496144788495, 'y': -5.396667405051684}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,462] Trial 295 finished with value: 0.209583363575796 and parameters: {'x': 3.414762508433562, 'y': -4.806207778345736}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,470] Trial 296 finished with value: 6.675291917781856 and parameters: {'x': 1.974676038050327, 'y': -2.628502015427025}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,473] Trial 297 finished with value: 164.25933810622698 and parameters: {'x': 1.504304001353537, 'y': 7.728795370570615}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,477] Trial 298 finished with value: 1.112204162608607 and parameters: {'x': 2.966203326530529, 'y': -6.054069232769368}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,483] Trial 299 finished with value: 94.72361628341702 and parameters: {'x': -6.510904212304913, 'y': -7.065506559606547}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,488] Trial 300 finished with value: 37.61772394968478 and parameters: {'x': 3.7764944163944243, 'y': 1.083977348001311}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,490] Trial 301 finished with value: 2.2662523363776628 and parameters: {'x': 4.180517114847999, 'y': -4.065852432466572}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,490] Trial 302 finished with value: 0.27894275940845115 and parameters: {'x': 2.647010050935734, 'y': -5.392862387189278}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,490] Trial 303 finished with value: 0.22147698486759532 and parameters: {'x': 3.422417150215698, 'y': -4.792537386328901}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,506] Trial 304 finished with value: 3.664395427279609 and parameters: {'x': 2.329523339551944, 'y': -3.206997915485308}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,506] Trial 305 finished with value: 2.0259541186570944 and parameters: {'x': 3.1116009475154494, 'y': -6.418978275792392}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,506] Trial 306 finished with value: 0.7225488198743871 and parameters: {'x': 2.616385694956697, 'y': -4.241456075866051}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,519] Trial 307 finished with value: 7.6806467314732 and parameters: {'x': 3.5048330516163455, 'y': -7.7250303340456465}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,522] Trial 308 finished with value: 0.6410259826522383 and parameters: {'x': 2.914485306433705, 'y': -5.79606106539417}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,522] Trial 309 finished with value: 81.60515388656131 and parameters: {'x': 4.514577002209067, 'y': 3.905684161867673}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,522] Trial 310 finished with value: 2.475260484623089 and parameters: {'x': 2.164663687400239, 'y': -3.666780689655553}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,537] Trial 311 finished with value: 1.0061043858777823 and parameters: {'x': 3.9903278293518234, 'y': -4.840766912078275}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,539] Trial 312 finished with value: 0.1389086317177504 and parameters: {'x': 3.197585578790977, 'y': -5.3160198898354105}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,539] Trial 313 finished with value: 0.30641552089977964 and parameters: {'x': 3.3790423226765833, 'y': -5.40341348331423}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,539] Trial 314 finished with value: 1.8326138958763771 and parameters: {'x': 3.124958389263556, 'y': -6.347961162952789}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,554] Trial 315 finished with value: 0.5935743124026603 and parameters: {'x': 3.7157757511005496, 'y': -5.285025238424783}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,557] Trial 316 finished with value: 1.1304624623113089 and parameters: {'x': 2.5478194981005635, 'y': -5.962286472945184}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,557] Trial 317 finished with value: 0.5966533021335505 and parameters: {'x': 3.228423347029405, 'y': -4.262113777967474}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,557] Trial 318 finished with value: 0.025813332786708054 and parameters: {'x': 2.84982614974857, 'y': -5.057106457492732}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,573] Trial 319 finished with value: 1.0356137775505592 and parameters: {'x': 4.014289435652497, 'y': -4.917351840466358}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,573] Trial 320 finished with value: 0.4493307464194012 and parameters: {'x': 2.937337452502877, 'y': -5.6673860588599165}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,582] Trial 321 finished with value: 1.6066957461398146 and parameters: {'x': 3.568854583271254, 'y': -3.8672598668577587}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,587] Trial 322 finished with value: 72.01466245049762 and parameters: {'x': 1.6760896332458863, 'y': -13.38223859069274}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,589] Trial 323 finished with value: 6.892247501363757 and parameters: {'x': 5.03178659937066, 'y': -6.662555477565054}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,597] Trial 324 finished with value: 0.1802768834132825 and parameters: {'x': 2.88148382726148, 'y': -4.592285884212116}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,597] Trial 325 finished with value: 0.5290774923458461 and parameters: {'x': 2.298031592809886, 'y': -5.190572421018416}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,605] Trial 326 finished with value: 3.7775269524036195 and parameters: {'x': 3.3896966768880192, 'y': -3.095882500362424}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,609] Trial 327 finished with value: 1.452735954293715 and parameters: {'x': 1.9585558817971307, 'y': -4.393262739767564}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,618] Trial 328 finished with value: 1.0196427970550395 and parameters: {'x': 3.7896965002407024, 'y': -5.6293029751738235}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,622] Trial 329 finished with value: 1.697251108918151 and parameters: {'x': 3.128494053740307, 'y': -3.703566281265589}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,626] Trial 330 finished with value: 314.35216381413244 and parameters: {'x': 4.344561597490766, 'y': 12.678922985427747}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,631] Trial 331 finished with value: 0.17151726019261035 and parameters: {'x': 2.587275600005997, 'y': -4.965709624641884}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,635] Trial 332 finished with value: 1.1560809439735829 and parameters: {'x': 2.9739801593091233, 'y': -6.074897163390063}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,638] Trial 333 finished with value: 4.7796585726690575 and parameters: {'x': 2.466484380636337, 'y': -7.120146140379022}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,638] Trial 334 finished with value: 0.5428470837618816 and parameters: {'x': 3.3851579377516474, 'y': -4.371907294463007}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,638] Trial 335 finished with value: 0.08075609898401107 and parameters: {'x': 2.850023389717558, 'y': -5.241377536966884}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,653] Trial 336 finished with value: 1.339982609263474 and parameters: {'x': 2.001751433032312, 'y': -5.586073722163373}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,660] Trial 337 finished with value: 0.09198569245254729 and parameters: {'x': 2.7294477412199054, 'y': -5.13706628951546}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,671] Trial 338 finished with value: 0.21188409391052576 and parameters: {'x': 2.5522558292391233, 'y': -4.893185902334099}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,676] Trial 339 finished with value: 1.2632538199402197 and parameters: {'x': 2.2181160135967053, 'y': -4.192589787192215}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,689] Trial 340 finished with value: 1.625257435426253 and parameters: {'x': 2.7411128443931467, 'y': -6.2482927846014515}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,694] Trial 341 finished with value: 2.242682354119081 and parameters: {'x': 1.5042388505504576, 'y': -5.073354876569077}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,703] Trial 342 finished with value: 2.135481866447669 and parameters: {'x': 2.940137794123833, 'y': -3.5398978177006555}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,706] Trial 343 finished with value: 1.0953963662263293 and parameters: {'x': 2.411073157769244, 'y': -5.865194510342293}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,706] Trial 344 finished with value: 1.5734920455895889 and parameters: {'x': 1.8415480777414883, 'y': -4.518875079210037}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,706] Trial 345 finished with value: 3.585617442834847 and parameters: {'x': 2.7498597060248064, 'y': -6.876978230072169}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,722] Trial 346 finished with value: 6.412389265168546 and parameters: {'x': 3.5772746529232586, 'y': -2.5344081359112014}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,722] Trial 347 finished with value: 1.2482132355573472 and parameters: {'x': 3.225249587737069, 'y': -3.905707599047847}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,722] Trial 348 finished with value: 0.6239358569501093 and parameters: {'x': 2.2539706411330434, 'y': -5.2595689747613665}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,735] Trial 349 finished with value: 0.21709508331002553 and parameters: {'x': 2.7794936432452424, 'y': -4.589546555696302}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,738] Trial 350 finished with value: 1.5951574787602951 and parameters: {'x': 4.017177300228381, 'y': -5.748670701083191}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,746] Trial 351 finished with value: 2.034700219093669 and parameters: {'x': 3.237367779765256, 'y': -6.4065407054980605}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,746] Trial 352 finished with value: 0.6031982991084259 and parameters: {'x': 3.7757969744413504, 'y': -5.036569844900854}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,756] Trial 353 finished with value: 230.74138147228 and parameters: {'x': 2.7367694087936436, 'y': 10.18789291271614}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,758] Trial 354 finished with value: 1.6902575955186296 and parameters: {'x': 2.3401407948346873, 'y': -3.8798020599567096}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,758] Trial 355 finished with value: 3.16517494307083 and parameters: {'x': 1.2735079871924582, 'y': -5.429418528690359}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,768] Trial 356 finished with value: 0.22856501437856228 and parameters: {'x': 3.0935155009116677, 'y': -4.531150487397286}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,775] Trial 357 finished with value: 4.771830292732777 and parameters: {'x': 1.9130430489086574, 'y': -3.1051768211236728}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,775] Trial 358 finished with value: 1.5362934141246 and parameters: {'x': 3.628908038430089, 'y': -6.068067457290324}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,775] Trial 359 finished with value: 0.0950321955279078 and parameters: {'x': 2.6965305980441907, 'y': -4.945791904622176}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,789] Trial 360 finished with value: 1.0623768439460848 and parameters: {'x': 3.2476678064715205, 'y': -3.9994813836896035}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,796] Trial 361 finished with value: 0.28293643118021955 and parameters: {'x': 2.8989320653856865, 'y': -5.522227635972108}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,804] Trial 362 finished with value: 0.6501335221985469 and parameters: {'x': 2.342799302026366, 'y': -4.532858945519113}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,807] Trial 363 finished with value: 2.9377711778492017 and parameters: {'x': 3.5766911081181534, 'y': -6.614062744649866}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,807] Trial 364 finished with value: 0.016700626656755705 and parameters: {'x': 2.926885968697119, 'y': -5.1065596785064455}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,818] Trial 365 finished with value: 9.939189013235195 and parameters: {'x': -0.06804847112723648, 'y': -5.7254430315669325}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,823] Trial 366 finished with value: 5.763869037484 and parameters: {'x': 2.7393348409941827, 'y': -7.386613230576851}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,823] Trial 367 finished with value: 0.9835529912301811 and parameters: {'x': 2.0128180022758095, 'y': -5.094998392615126}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,823] Trial 368 finished with value: 1.3736747858635974 and parameters: {'x': 3.0507352633653895, 'y': -6.1709401004811655}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,837] Trial 369 finished with value: 1.1399137106269936 and parameters: {'x': 2.311938639504523, 'y': -4.1836145059960295}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,839] Trial 370 finished with value: 3.870549812051153 and parameters: {'x': 4.121693473763549, 'y': -3.3837223125442164}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,839] Trial 371 finished with value: 0.11872037516340789 and parameters: {'x': 2.6567249832683086, 'y': -5.0297092250195945}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,839] Trial 372 finished with value: 1.8870628806496315 and parameters: {'x': 1.7681666584652107, 'y': -5.60798807499232}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,856] Trial 373 finished with value: 0.13712513485974848 and parameters: {'x': 2.637664031730081, 'y': -5.0764053725705764}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,857] Trial 374 finished with value: 2.6664495499265066 and parameters: {'x': 2.5410010106690892, 'y': -6.567089492568854}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,857] Trial 375 finished with value: 5.802332232013147 and parameters: {'x': 0.6064346598553945, 'y': -5.27051283605697}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,873] Trial 376 finished with value: 1.699263879564946 and parameters: {'x': 2.128583303622956, 'y': -5.969482759434259}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,887] Trial 377 finished with value: 0.03257448170655131 and parameters: {'x': 2.8218735180218895, 'y': -5.029076418704049}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,891] Trial 378 finished with value: 130.05891522123216 and parameters: {'x': -8.388232719960023, 'y': -4.394136370736689}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,891] Trial 379 finished with value: 2.4236657093030525 and parameters: {'x': 1.4486426450819498, 'y': -4.869784537612757}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,908] Trial 380 finished with value: 1.578378765779104 and parameters: {'x': 2.6543762088520713, 'y': -3.7921411668693907}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,908] Trial 381 finished with value: 27.58962747465743 and parameters: {'x': 2.2771249001036065, 'y': 0.20260310465897569}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,908] Trial 382 finished with value: 0.47294905974435775 and parameters: {'x': 2.8127483425807314, 'y': -5.661729458720174}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,924] Trial 383 finished with value: 0.42049782323363455 and parameters: {'x': 2.9854018478041433, 'y': -4.351706303296028}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,925] Trial 384 finished with value: 1.4829621750244228 and parameters: {'x': 1.7824907683400368, 'y': -4.974831649891401}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,938] Trial 385 finished with value: 1.5519644036824787 and parameters: {'x': 2.4227705738294953, 'y': -6.103979435155089}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,940] Trial 386 finished with value: 0.07507614903816115 and parameters: {'x': 2.8640531461645664, 'y': -5.237896199991527}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,940] Trial 387 finished with value: 20.340250421145065 and parameters: {'x': -1.0834464708457858, 'y': -6.914605792554218}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,940] Trial 388 finished with value: 35.240992900170156 and parameters: {'x': 3.384883203950493, 'y': -10.92392250282589}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,956] Trial 389 finished with value: 0.8699691740774903 and parameters: {'x': 3.2232100736639193, 'y': -4.094380633437845}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,959] Trial 390 finished with value: 0.34916150169162025 and parameters: {'x': 2.9256916279316165, 'y': -5.586207955875871}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,959] Trial 391 finished with value: 2.8423222189011037 and parameters: {'x': 2.1197442392875216, 'y': -3.5621293470434834}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,972] Trial 392 finished with value: 0.5751230302857822 and parameters: {'x': 3.705877398582699, 'y': -4.722763407076368}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,972] Trial 393 finished with value: 1.3414743369925168 and parameters: {'x': 2.8582765497830867, 'y': -6.149516768320989}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,972] Trial 394 finished with value: 0.3866813293305155 and parameters: {'x': 2.5068833862779005, 'y': -5.37883681790682}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,972] Trial 395 finished with value: 0.3994673847646132 and parameters: {'x': 3.3694795021772896, 'y': -4.4872112693950506}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,988] Trial 396 finished with value: 4.32849207707694 and parameters: {'x': 0.921731602291318, 'y': -5.096397843141474}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,988] Trial 397 finished with value: 9.032485290012428 and parameters: {'x': 3.1039464764738582, 'y': -8.003611229843353}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:07,999] Trial 398 finished with value: 5.368393820663358 and parameters: {'x': 1.990378551055585, 'y': -2.914560393946941}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,003] Trial 399 finished with value: 3.098778052981216 and parameters: {'x': 3.798342747818632, 'y': -6.56889353048147}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,003] Trial 400 finished with value: 0.9124293872488626 and parameters: {'x': 2.60351112348322, 'y': -4.130962625632635}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,003] Trial 401 finished with value: 0.35906412515043046 and parameters: {'x': 2.954306682430777, 'y': -5.597474891422182}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,003] Trial 402 finished with value: 2.5090984722795344 and parameters: {'x': 4.573381638708948, 'y': -4.816782393714253}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,020] Trial 403 finished with value: 1.26829985303805 and parameters: {'x': 3.4928095071519154, 'y': -6.012639443582333}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,020] Trial 404 finished with value: 0.7931477269581884 and parameters: {'x': 2.2555550846029315, 'y': -4.51117539454561}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,020] Trial 405 finished with value: 2.5139020297033663 and parameters: {'x': 2.976367005491702, 'y': -3.414647196591895}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,037] Trial 406 finished with value: 27.532174763987445 and parameters: {'x': 6.201309825588613, 'y': -0.8426222008846431}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,037] Trial 407 finished with value: 0.3836043185767693 and parameters: {'x': 2.506777370906282, 'y': -5.374614143788846}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,048] Trial 408 finished with value: 1.8903545070995185 and parameters: {'x': 3.9376646734329577, 'y': -3.9944456915236337}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,054] Trial 409 finished with value: 55.9504928012692 and parameters: {'x': 1.738668911363872, 'y': 2.372892016441662}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,054] Trial 410 finished with value: 21.398996230412656 and parameters: {'x': 3.291374953101515, 'y': -9.616719275320706}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,054] Trial 411 finished with value: 8.064219107106796 and parameters: {'x': 2.744913816523085, 'y': -2.1717231136068063}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,054] Trial 412 finished with value: 0.7123581107134144 and parameters: {'x': 2.1584674277684273, 'y': -4.935339033515365}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,073] Trial 413 finished with value: 0.8617051049937923 and parameters: {'x': 3.287176913204434, 'y': -5.882742615667877}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,086] Trial 414 finished with value: 4.3626396212137495 and parameters: {'x': 3.7445355248578425, 'y': -6.951488271406827}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,096] Trial 415 finished with value: 0.09139765995381686 and parameters: {'x': 2.854312794072026, 'y': -5.264901676066266}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,108] Trial 416 finished with value: 2.0517878445216637 and parameters: {'x': 3.486083101086499, 'y': -6.3474090185833685}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,122] Trial 417 finished with value: 0.3384329402226526 and parameters: {'x': 2.999221824096888, 'y': -5.581749374443081}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,132] Trial 418 finished with value: 15.722507057536351 and parameters: {'x': 6.916803025744358, 'y': -4.382617529357857}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,138] Trial 419 finished with value: 3.139095626858453 and parameters: {'x': 4.103394895314596, 'y': -3.6137765938160813}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,143] Trial 420 finished with value: 0.5189792908198182 and parameters: {'x': 2.417024795935316, 'y': -5.42322476565716}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,148] Trial 421 finished with value: 0.08318519424520676 and parameters: {'x': 3.0510618634011264, 'y': -4.716137567911477}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,154] Trial 422 finished with value: 0.5885054920185389 and parameters: {'x': 3.0015814992031737, 'y': -4.232860514066178}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,159] Trial 423 finished with value: 2.190536348903204 and parameters: {'x': 2.047590475039659, 'y': -6.132895602281173}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,163] Trial 424 finished with value: 19.561260653842382 and parameters: {'x': 7.421185457511589, 'y': -4.88008417898198}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,168] Trial 425 finished with value: 0.30565826085679687 and parameters: {'x': 2.667939770363618, 'y': -5.442034234817429}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,173] Trial 426 finished with value: 1.7096687984351042 and parameters: {'x': 3.5134157308837897, 'y': -3.797472210002543}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,178] Trial 427 finished with value: 3.1775624238606652 and parameters: {'x': 1.2504669931216197, 'y': -4.658391039778289}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,181] Trial 428 finished with value: 2.1824365239272243 and parameters: {'x': 2.8725152341745512, 'y': -6.47179623535653}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,189] Trial 429 finished with value: 6.19538653417804 and parameters: {'x': 2.2829169315437627, 'y': -7.383522269061363}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,194] Trial 430 finished with value: 2.4235599775365504 and parameters: {'x': 1.6272140872308531, 'y': -5.734179007626294}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,196] Trial 431 finished with value: 0.05131910160323288 and parameters: {'x': 3.178799282400934, 'y': -5.139103983466125}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,206] Trial 432 finished with value: 0.7579786217928122 and parameters: {'x': 3.770656767446991, 'y': -5.4050515628669595}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,211] Trial 433 finished with value: 1.5279077584049012 and parameters: {'x': 3.242058479369464, 'y': -6.212153229162982}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,213] Trial 434 finished with value: 1.8253498060815139 and parameters: {'x': 4.349412355321242, 'y': -5.06660406434965}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,223] Trial 435 finished with value: 0.7437387512470344 and parameters: {'x': 2.5576746138440507, 'y': -4.25967101636568}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,228] Trial 436 finished with value: 0.6595859084205556 and parameters: {'x': 3.1856141113969283, 'y': -5.7906537232384885}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,233] Trial 437 finished with value: 3.9511506386131794 and parameters: {'x': 3.6607534453433406, 'y': -6.874714784461915}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,239] Trial 438 finished with value: 3.917113933178525 and parameters: {'x': 2.8275095277868645, 'y': -3.0283608417932517}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,244] Trial 439 finished with value: 0.36143319017110387 and parameters: {'x': 2.4043260957675647, 'y': -5.081276011144688}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,249] Trial 440 finished with value: 1.3263830770107425 and parameters: {'x': 1.9800804782339272, 'y': -4.465072672102829}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,255] Trial 441 finished with value: 7.476761789049666 and parameters: {'x': 5.515171170788582, 'y': -6.072695562908535}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,260] Trial 442 finished with value: 1.7753582712476683 and parameters: {'x': 3.2757713222969773, 'y': -3.696424743619976}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,261] Trial 443 finished with value: 0.07069747559260167 and parameters: {'x': 2.8697131196908097, 'y': -5.231781803452947}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,270] Trial 444 finished with value: 0.37457488555317775 and parameters: {'x': 3.577120704319759, 'y': -5.203731632788439}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,275] Trial 445 finished with value: 0.341491906884649 and parameters: {'x': 2.961975846781015, 'y': -4.416865306591498}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,280] Trial 446 finished with value: 82.11919626041909 and parameters: {'x': 3.9457493665934487, 'y': 4.012477705714849}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,285] Trial 447 finished with value: 53.16253292184791 and parameters: {'x': -4.252814545180008, 'y': -5.7478061881752724}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,291] Trial 448 finished with value: 0.3352125098908472 and parameters: {'x': 2.46555676954486, 'y': -4.777327722175567}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,292] Trial 449 finished with value: 2.1981633204713673 and parameters: {'x': 3.2333528761557773, 'y': -6.4641413031743875}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,292] Trial 450 finished with value: 1.056048942648186 and parameters: {'x': 2.840847599638307, 'y': -3.9847564547817615}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,306] Trial 451 finished with value: 0.7355985866174676 and parameters: {'x': 2.189024278973349, 'y': -5.279136107522426}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,311] Trial 452 finished with value: 0.365213655285377 and parameters: {'x': 3.507982645662585, 'y': -4.67263584956349}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,316] Trial 453 finished with value: 0.7826308803088509 and parameters: {'x': 2.659674650162873, 'y': -5.816584065829776}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,322] Trial 454 finished with value: 4.1203933693340655 and parameters: {'x': 4.155025009224261, 'y': -3.330775450276218}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,327] Trial 455 finished with value: 0.03574571466372903 and parameters: {'x': 3.1197472485461732, 'y': -5.146308957789159}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,332] Trial 456 finished with value: 3.3397355996910436 and parameters: {'x': 3.141695701818689, 'y': -6.821992845149825}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,338] Trial 457 finished with value: 0.8376511129458115 and parameters: {'x': 3.691923074273355, 'y': -5.599077267331953}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,344] Trial 458 finished with value: 0.9763844797250089 and parameters: {'x': 3.2512523019520247, 'y': -4.044355316820725}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,345] Trial 459 finished with value: 2.2957917894983773 and parameters: {'x': 3.9123489926618413, 'y': -6.209715299187086}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,355] Trial 460 finished with value: 2.634232857158503 and parameters: {'x': 4.616803138158241, 'y': -5.142057979713096}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,371] Trial 461 finished with value: 6.450897419021301 and parameters: {'x': 3.018730363701189, 'y': -7.539792627853093}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,373] Trial 462 finished with value: 0.6045915704926006 and parameters: {'x': 3.586316953208509, 'y': -4.489290688480334}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,394] Trial 463 finished with value: 0.5460954700835078 and parameters: {'x': 2.496110959625817, 'y': -5.54054722742263}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,404] Trial 464 finished with value: 1.2143341552763844 and parameters: {'x': 1.906275301590176, 'y': -4.865462126653035}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,416] Trial 465 finished with value: 0.6982379248778584 and parameters: {'x': 2.967790643721487, 'y': -4.165014681418899}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,422] Trial 466 finished with value: 1.2567308879705095 and parameters: {'x': 3.3146384104056232, 'y': -6.075980278010676}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,427] Trial 467 finished with value: 0.5374564116231714 and parameters: {'x': 2.353388072323325, 'y': -5.345469863532879}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,431] Trial 468 finished with value: 5.930899564535046 and parameters: {'x': 2.870192169083654, 'y': -2.5681181172664163}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,438] Trial 469 finished with value: 14.624806004092193 and parameters: {'x': 4.214986065096156, 'y': -8.626101882974933}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,443] Trial 470 finished with value: 2.5857735544262646 and parameters: {'x': 3.4575341860736835, 'y': -6.541569337720544}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,447] Trial 471 finished with value: 2.4169292480282456 and parameters: {'x': 2.57250812214995, 'y': -3.505282654679995}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,453] Trial 472 finished with value: 0.7875466411214836 and parameters: {'x': 2.1545135026885442, 'y': -4.73037206378884}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,461] Trial 473 finished with value: 1.9934828787334413 and parameters: {'x': 1.6102059413142118, 'y': -5.248908322832173}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,466] Trial 474 finished with value: 0.6980861760917207 and parameters: {'x': 3.0818928518585835, 'y': -4.168507524444034}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,472] Trial 475 finished with value: 1.323427428034253 and parameters: {'x': 3.8323489703723, 'y': -5.7941175099155195}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,472] Trial 476 finished with value: 0.1173166438739049 and parameters: {'x': 2.847143988023633, 'y': -4.693484611354363}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,472] Trial 477 finished with value: 0.6568789318148404 and parameters: {'x': 3.3888680441826464, 'y': -5.7110981479573715}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,488] Trial 478 finished with value: 25.951311922574526 and parameters: {'x': -1.9381171272674234, 'y': -3.7484764644791317}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,493] Trial 479 finished with value: 94.74520678039131 and parameters: {'x': 2.5039685354092684, 'y': -14.72106782028226}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,493] Trial 480 finished with value: 3.8532660420590226 and parameters: {'x': 3.0911194231875347, 'y': -6.960857795144001}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,502] Trial 481 finished with value: 0.5916856014433666 and parameters: {'x': 2.2318473928556677, 'y': -5.040338239683105}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,504] Trial 482 finished with value: 0.7837834140750636 and parameters: {'x': 3.633925123006264, 'y': -4.382001332933026}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,504] Trial 483 finished with value: 1.6680833336425713 and parameters: {'x': 2.810388928842963, 'y': -6.277548815246311}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,518] Trial 484 finished with value: 1.2452217325021075 and parameters: {'x': 1.9143495348161732, 'y': -5.258040306828697}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,522] Trial 485 finished with value: 3.8366513912754927 and parameters: {'x': 3.23078417851434, 'y': -3.054906157990583}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,522] Trial 486 finished with value: 27.3614129351684 and parameters: {'x': 2.6201147441018087, 'y': -10.217001066467168}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,529] Trial 487 finished with value: 1.8714213649704794 and parameters: {'x': 3.992428614090352, 'y': -5.941544906472964}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,538] Trial 488 finished with value: 0.29314304623392146 and parameters: {'x': 3.449340128763198, 'y': -4.697946205259735}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,544] Trial 489 finished with value: 1.045386023276094 and parameters: {'x': 2.8135727831259274, 'y': -3.994698594408283}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,544] Trial 490 finished with value: 0.694917685138758 and parameters: {'x': 2.2636155929191166, 'y': -5.390711773750029}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,555] Trial 491 finished with value: 0.1792305387682942 and parameters: {'x': 3.1318489958494995, 'y': -4.597698643972242}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,555] Trial 492 finished with value: 0.9261319181004348 and parameters: {'x': 3.527750804912319, 'y': -5.804742819797005}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,555] Trial 493 finished with value: 2.3854984376369774 and parameters: {'x': 2.5783991455485715, 'y': -6.485850314521218}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,573] Trial 494 finished with value: 1.9745669216571002 and parameters: {'x': 4.404496646516404, 'y': -5.044227724124983}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,573] Trial 495 finished with value: 1.7425536155419232 and parameters: {'x': 2.9729250073196485, 'y': -3.6802195029804077}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,586] Trial 496 finished with value: 49.458978864019436 and parameters: {'x': 9.989073499750821, 'y': -4.217804066042118}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,600] Trial 497 finished with value: 237.54058544385907 and parameters: {'x': 1.7928038265316806, 'y': 10.365001231455288}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,612] Trial 498 finished with value: 0.5242840806314025 and parameters: {'x': 3.683031280009904, 'y': -5.240317188647493}. Best is trial 261 with value: 0.0045083209950914725.\n",
      "[I 2025-09-25 16:06:08,622] Trial 499 finished with value: 5.138942661660015 and parameters: {'x': 2.376113329584782, 'y': -7.17938250064972}. Best is trial 261 with value: 0.0045083209950914725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0045083209950914725\n",
      "{'x': 2.99235703569182, 'y': -4.933292383555734}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# 목적 함수 정의\n",
    "def objective(trial):\n",
    "    x=trial.suggest_uniform('x', -10, 10) # 'x'는 라벨명\n",
    "    y=trial.suggest_uniform('y', -15, 15)\n",
    "\n",
    "    return (x-3)**2 + (y+5)**2 # 임의의 loss함수 설정. 최솟값이 x=3, y=-5일 때로 나오는지 보면 됨\n",
    "\n",
    "# 스터디 생성. = 최적화 과정을 관리하는 핵심 객체\n",
    "# minimize: 최적화 시키는 것이, 반환되는 것이 return 함수를 최소화시키는('minimize') 방향으로 스터디를 할 것\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# 최적화 실행\n",
    "study.optimize(objective, n_trials=500)\n",
    "# 차례로 목적 함수, 반복할 횟수(500번) 넘김\n",
    "# (hyperopt의 fmin()은 best 최솟값을 반환함. 하지만 study.optimize는 반환 x)\n",
    "\n",
    "# 결과 확인\n",
    "print(study.best_value)\n",
    "print(study.best_params)\n",
    "# 3과 -5 근사치가 나옴!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4659b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "x (FloatDistribution): 0.0568510415031053<extra></extra>",
          "y (FloatDistribution): 0.9431489584968946<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.06",
          "0.94"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0568510415031053,
          0.9431489584968946
         ],
         "y": [
          "x",
          "y"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna.visualization as vis\n",
    "import plotly\n",
    "\n",
    "vis.plot_param_importances(study).show()\n",
    "# 하이퍼 파라미터 중요도 시각화 내장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b081a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          52.62668740461417,
          7.379249330643109,
          49.25554566801907,
          89.76411280861431,
          381.50009000247735,
          73.4719429978145,
          76.60330997064975,
          124.54808441859954,
          138.17259143784872,
          100.27713707230214,
          157.19342234322397,
          109.77408333040839,
          7.811969975779277,
          13.912774689013645,
          47.86996851142551,
          25.36131065505904,
          2.4273183621822665,
          33.11971729173059,
          68.57267597114445,
          297.57618261345857,
          1.974308471978774,
          2.56960378478389,
          4.059818839702864,
          61.56561775142973,
          16.647401954782026,
          23.58391294042414,
          27.268297713193967,
          3.1237248539823272,
          7.061059782265072,
          79.20472363818763,
          27.855033478102065,
          2.3650102179851573,
          14.719889602199208,
          1.3506057350318232,
          20.86738074599292,
          34.641194818430904,
          38.74421508277979,
          1.017678493558336,
          39.77970629648366,
          64.72528363371416,
          19.315435479881792,
          1.1616766932507034,
          2.446820083128908,
          15.590615095240894,
          26.585793904205833,
          2.052892451873734,
          3.7070360209024913,
          363.4576302338131,
          61.14417630126178,
          16.638670358753043,
          55.29017652178108,
          4.802574656519962,
          2.026268415920314,
          1.2655202056087065,
          9.599031227702945,
          6.684987610418615,
          19.022574447185185,
          0.7122529236774834,
          7.259267346189489,
          27.015161309302815,
          16.404011492713973,
          6.792962720028546,
          4.15303996690829,
          4.331561281831778,
          1.7733026458394143,
          12.042609561738493,
          30.47552742553698,
          0.3607815821029822,
          4.727028270709517,
          17.506859632375257,
          15.143435204089522,
          0.16793856063344498,
          1.3554403597070563,
          5.199151062933531,
          5.600171309256986,
          102.19097294768069,
          2.5485679058691333,
          3.750894310809988,
          11.168537303766934,
          19.288345553485076,
          35.4629337696136,
          1.6820765215666906,
          8.493951267149594,
          1.3946859642467406,
          0.8112655921594513,
          2.134267418573301,
          15.658525917131206,
          185.60777471576193,
          1.478245543127559,
          7.632329786213663,
          56.45906213043369,
          0.831872814040295,
          0.9875560416091038,
          7.584047766976003,
          172.17342529101037,
          1.0412968842958907,
          2.0220769493327886,
          0.7680601200373436,
          2.2397591383200024,
          5.922793301730854,
          4.578915765037818,
          0.6086732010890701,
          4.656323330553556,
          9.953496224764239,
          0.930419448068964,
          12.92003535251775,
          14.500584433443281,
          0.5279270799158655,
          0.3266352551528498,
          0.541290183904662,
          2.1633986320897898,
          0.7298899734531056,
          0.4023902542331037,
          0.29884855700629126,
          0.6661304245085451,
          5.369988826970671,
          13.50744869213913,
          2.566776525237677,
          22.532967351308283,
          6.917934941357558,
          0.29972417426136133,
          0.27136814498369766,
          0.4081337732124141,
          0.8394933883054085,
          10.209431383184903,
          7.222398151295955,
          7.54440351309321,
          0.5894400309673653,
          5.48391180735442,
          0.28074797760425596,
          3.1678201158998873,
          0.7353961841325998,
          0.19196283023712912,
          2.11441239475982,
          59.558862551467804,
          5.645025194713784,
          2.4608375441638946,
          4.416525710402219,
          0.07180734190285593,
          0.10854592709155812,
          44.019261169214815,
          0.5709146525311541,
          1.6654722412980592,
          1.105772336257482,
          9.891199512095561,
          0.20269698006311104,
          1.4820885652740454,
          4.438734655441683,
          4.591770467680805,
          1.7279621691134677,
          88.25028270372893,
          0.6439708169096441,
          0.1802398896384514,
          2.178331785483067,
          1.2642706007831406,
          0.06689799444172187,
          0.03639580898820557,
          0.7983916160412199,
          310.1677967715079,
          8.435449250036948,
          1.5284882522499221,
          1.680239070887018,
          0.7846398014483101,
          3.0986202640112683,
          30.111316430468914,
          3.022236351174908,
          0.23195992412493602,
          0.6343901732237958,
          130.72950368889758,
          1.2626271986839894,
          108.41014497088871,
          0.26426145530496503,
          0.23955806136683322,
          0.38283416667750786,
          65.0080811077372,
          3.600122586446278,
          1.670406213959178,
          0.37415696468665954,
          3.4041777291129875,
          0.3628906915118921,
          3.2943073788487527,
          0.528077188755277,
          0.8091957597495415,
          0.9925600330476423,
          1.2013095132561924,
          0.08547034751092988,
          2.555498678302449,
          0.1482957899773881,
          0.7878045364589904,
          3.1195742869366545,
          4.165749946455089,
          0.029504690643549762,
          0.19500759974470513,
          0.3669755195476567,
          0.10951892382978047,
          1.8528767658917191,
          0.03582135472576679,
          3.7831069551978085,
          1.4427518148929004,
          1.8641528908865728,
          0.17538505677139718,
          0.1584851059956493,
          0.2504133644703419,
          0.41090724215437774,
          1.5873839863540422,
          0.0454237434731593,
          0.8147832073950345,
          1.3565371371094088,
          0.9564063148702708,
          2.2543871536936635,
          2.3327002494774387,
          0.09343360262132915,
          0.05581696820148409,
          0.11310604648327155,
          0.3982442656589895,
          0.8500063072511539,
          0.5417489633255178,
          0.874673459574546,
          1.3150570062801374,
          1.151345018704742,
          0.3514976543009164,
          0.19794348887472268,
          0.32553446053712287,
          1.2081460786709233,
          2.0735095587049526,
          0.5438106513629569,
          0.694167683954842,
          1.022690110162614,
          0.537003685619911,
          0.3633920516612743,
          3.0587191826247504,
          0.20657130455817077,
          0.35887581953181735,
          1.620203727299678,
          0.03403804510078524,
          2.8062073515369166,
          0.8655966652218622,
          0.9676992772395803,
          0.1799375777801961,
          0.39832461808901387,
          26.330263199460923,
          0.31643138368038204,
          0.47001705592421616,
          0.17268889999426468,
          0.471133841271278,
          0.037779958260075124,
          0.9758970093356409,
          2.0316648346609667,
          0.09493715982729685,
          2.4167995127091086,
          0.08072757722477697,
          1.7614504032589953,
          1.5842982755501327,
          0.6708064889590847,
          0.7724169255341783,
          44.17836063889536,
          1.7780803288093132,
          1.6836938577140672,
          1.9333979587965606,
          1.039009610693995,
          0.7659519947232067,
          0.0045083209950914725,
          6.032861118431808,
          0.7822373393274593,
          0.34572836535841267,
          4.269458985629617,
          0.35314706030870374,
          2.487419353270995,
          1.989455851615911,
          2.724642241612057,
          0.5341355447797183,
          0.21947962465755005,
          1.215265274170585,
          0.960042620623405,
          5.696556822076694,
          0.7622571472442542,
          0.5025489725230268,
          3.344374717976403,
          0.3069509321123947,
          1.6187028722390862,
          1.8598009310810586,
          2.3434879961613957,
          0.3411877591029418,
          0.31003143536871114,
          38.95092200809324,
          0.34576049219748856,
          0.30321371383516593,
          1.2501934791104963,
          2.0308115965588858,
          0.708613491326668,
          0.8327305382429193,
          69.00202458873255,
          1.7017560334253676,
          0.29018328048974024,
          0.462605540254012,
          0.209583363575796,
          6.675291917781856,
          164.25933810622698,
          1.112204162608607,
          94.72361628341702,
          37.61772394968478,
          2.2662523363776628,
          0.27894275940845115,
          0.22147698486759532,
          3.664395427279609,
          2.0259541186570944,
          0.7225488198743871,
          7.6806467314732,
          0.6410259826522383,
          81.60515388656131,
          2.475260484623089,
          1.0061043858777823,
          0.1389086317177504,
          0.30641552089977964,
          1.8326138958763771,
          0.5935743124026603,
          1.1304624623113089,
          0.5966533021335505,
          0.025813332786708054,
          1.0356137775505592,
          0.4493307464194012,
          1.6066957461398146,
          72.01466245049762,
          6.892247501363757,
          0.1802768834132825,
          0.5290774923458461,
          3.7775269524036195,
          1.452735954293715,
          1.0196427970550395,
          1.697251108918151,
          314.35216381413244,
          0.17151726019261035,
          1.1560809439735829,
          4.7796585726690575,
          0.5428470837618816,
          0.08075609898401107,
          1.339982609263474,
          0.09198569245254729,
          0.21188409391052576,
          1.2632538199402197,
          1.625257435426253,
          2.242682354119081,
          2.135481866447669,
          1.0953963662263293,
          1.5734920455895889,
          3.585617442834847,
          6.412389265168546,
          1.2482132355573472,
          0.6239358569501093,
          0.21709508331002553,
          1.5951574787602951,
          2.034700219093669,
          0.6031982991084259,
          230.74138147228,
          1.6902575955186296,
          3.16517494307083,
          0.22856501437856228,
          4.771830292732777,
          1.5362934141246,
          0.0950321955279078,
          1.0623768439460848,
          0.28293643118021955,
          0.6501335221985469,
          2.9377711778492017,
          0.016700626656755705,
          9.939189013235195,
          5.763869037484,
          0.9835529912301811,
          1.3736747858635974,
          1.1399137106269936,
          3.870549812051153,
          0.11872037516340789,
          1.8870628806496315,
          0.13712513485974848,
          2.6664495499265066,
          5.802332232013147,
          1.699263879564946,
          0.03257448170655131,
          130.05891522123216,
          2.4236657093030525,
          1.578378765779104,
          27.58962747465743,
          0.47294905974435775,
          0.42049782323363455,
          1.4829621750244228,
          1.5519644036824787,
          0.07507614903816115,
          20.340250421145065,
          35.240992900170156,
          0.8699691740774903,
          0.34916150169162025,
          2.8423222189011037,
          0.5751230302857822,
          1.3414743369925168,
          0.3866813293305155,
          0.3994673847646132,
          4.32849207707694,
          9.032485290012428,
          5.368393820663358,
          3.098778052981216,
          0.9124293872488626,
          0.35906412515043046,
          2.5090984722795344,
          1.26829985303805,
          0.7931477269581884,
          2.5139020297033663,
          27.532174763987445,
          0.3836043185767693,
          1.8903545070995185,
          55.9504928012692,
          21.398996230412656,
          8.064219107106796,
          0.7123581107134144,
          0.8617051049937923,
          4.3626396212137495,
          0.09139765995381686,
          2.0517878445216637,
          0.3384329402226526,
          15.722507057536351,
          3.139095626858453,
          0.5189792908198182,
          0.08318519424520676,
          0.5885054920185389,
          2.190536348903204,
          19.561260653842382,
          0.30565826085679687,
          1.7096687984351042,
          3.1775624238606652,
          2.1824365239272243,
          6.19538653417804,
          2.4235599775365504,
          0.05131910160323288,
          0.7579786217928122,
          1.5279077584049012,
          1.8253498060815139,
          0.7437387512470344,
          0.6595859084205556,
          3.9511506386131794,
          3.917113933178525,
          0.36143319017110387,
          1.3263830770107425,
          7.476761789049666,
          1.7753582712476683,
          0.07069747559260167,
          0.37457488555317775,
          0.341491906884649,
          82.11919626041909,
          53.16253292184791,
          0.3352125098908472,
          2.1981633204713673,
          1.056048942648186,
          0.7355985866174676,
          0.365213655285377,
          0.7826308803088509,
          4.1203933693340655,
          0.03574571466372903,
          3.3397355996910436,
          0.8376511129458115,
          0.9763844797250089,
          2.2957917894983773,
          2.634232857158503,
          6.450897419021301,
          0.6045915704926006,
          0.5460954700835078,
          1.2143341552763844,
          0.6982379248778584,
          1.2567308879705095,
          0.5374564116231714,
          5.930899564535046,
          14.624806004092193,
          2.5857735544262646,
          2.4169292480282456,
          0.7875466411214836,
          1.9934828787334413,
          0.6980861760917207,
          1.323427428034253,
          0.1173166438739049,
          0.6568789318148404,
          25.951311922574526,
          94.74520678039131,
          3.8532660420590226,
          0.5916856014433666,
          0.7837834140750636,
          1.6680833336425713,
          1.2452217325021075,
          3.8366513912754927,
          27.3614129351684,
          1.8714213649704794,
          0.29314304623392146,
          1.045386023276094,
          0.694917685138758,
          0.1792305387682942,
          0.9261319181004348,
          2.3854984376369774,
          1.9745669216571002,
          1.7425536155419232,
          49.458978864019436,
          237.54058544385907,
          0.5242840806314025,
          5.138942661660015
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          52.62668740461417,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          7.379249330643109,
          2.4273183621822665,
          2.4273183621822665,
          2.4273183621822665,
          2.4273183621822665,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.974308471978774,
          1.3506057350318232,
          1.3506057350318232,
          1.3506057350318232,
          1.3506057350318232,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          1.017678493558336,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.7122529236774834,
          0.3607815821029822,
          0.3607815821029822,
          0.3607815821029822,
          0.3607815821029822,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.16793856063344498,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.07180734190285593,
          0.06689799444172187,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.03639580898820557,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.029504690643549762,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725,
          0.0045083209950914725
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.plot_optimization_history(study).show()\n",
    "# x축은 500번 시도\n",
    "# y축은 Objective Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8db075",
   "metadata": {},
   "source": [
    "- Optuna를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9016d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-25 16:36:44,224] A new study created in memory with name: no-name-4f64c071-2594-4dcf-a07a-9c928c033e82\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:44,389] Trial 0 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.11439170309660036, 'colsample_bytree': 0.6881162371298833}. Best is trial 0 with value: 0.9577464788732395.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:44,725] Trial 1 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.029825710212577544, 'colsample_bytree': 0.6723227756332911}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:44,898] Trial 2 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.06794709171669272, 'colsample_bytree': 0.9545395505854526}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:45,120] Trial 3 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.12518698128680808, 'colsample_bytree': 0.8822300698055108}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:45,278] Trial 4 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.08127228538662645, 'colsample_bytree': 0.7938857004429898}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:45,530] Trial 5 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.07441598019711072, 'colsample_bytree': 0.800745294357228}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:45,735] Trial 6 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.04972223858809972, 'colsample_bytree': 0.8698115281305587}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:45,897] Trial 7 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.037033800904747484, 'colsample_bytree': 0.6445607309587393}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:46,206] Trial 8 finished with value: 0.9530516431924881 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.010237727236865652, 'colsample_bytree': 0.7374414894671215}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:46,601] Trial 9 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.035434861352414825, 'colsample_bytree': 0.6986426479576744}. Best is trial 1 with value: 0.9624413145539906.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:46,871] Trial 10 finished with value: 0.971830985915493 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1596888246340826, 'colsample_bytree': 0.5232543561744274}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:47,134] Trial 11 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1861164429353296, 'colsample_bytree': 0.5368627949798654}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:47,376] Trial 12 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18698067204164512, 'colsample_bytree': 0.5036286018206485}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:47,585] Trial 13 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1952182138618901, 'colsample_bytree': 0.505655990292314}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:47,864] Trial 14 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.14718797896651475, 'colsample_bytree': 0.589709052205401}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:48,105] Trial 15 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.16222120692930464, 'colsample_bytree': 0.5912575029397391}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:48,355] Trial 16 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.16615231127082228, 'colsample_bytree': 0.5845689777904629}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:48,540] Trial 17 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.13684424778177964, 'colsample_bytree': 0.5374149944112784}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:48,812] Trial 18 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.16559186135662576, 'colsample_bytree': 0.6238879221082454}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,057] Trial 19 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.09607193049816723, 'colsample_bytree': 0.5524844805479229}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,237] Trial 20 finished with value: 0.971830985915493 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.18159960444898682, 'colsample_bytree': 0.5588719401554826}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,328] Trial 21 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.18278761087488765, 'colsample_bytree': 0.5497614522027263}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,499] Trial 22 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.19945123781835747, 'colsample_bytree': 0.6221978701614168}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,694] Trial 23 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.1496694546944567, 'colsample_bytree': 0.5062512967687871}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:49,927] Trial 24 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.17652229010538223, 'colsample_bytree': 0.5611385835664907}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:50,140] Trial 25 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.14982101927694746, 'colsample_bytree': 0.6449364771497743}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:50,419] Trial 26 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.17659157689180324, 'colsample_bytree': 0.7328797768375558}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:50,656] Trial 27 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.13235060718921635, 'colsample_bytree': 0.5963433944124983}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:50,836] Trial 28 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.16305734182279402, 'colsample_bytree': 0.5328912039725854}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:51,137] Trial 29 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.10941404454735737, 'colsample_bytree': 0.6941921416651139}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:51,247] Trial 30 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.12367919352483586, 'colsample_bytree': 0.5691986143635928}. Best is trial 10 with value: 0.971830985915493.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:51,516] Trial 31 finished with value: 0.9741784037558686 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18799187895664138, 'colsample_bytree': 0.5031793942770102}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:51,808] Trial 32 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18800122811582054, 'colsample_bytree': 0.5377498443055091}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:52,049] Trial 33 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.17184535904031858, 'colsample_bytree': 0.5164881089771615}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:52,272] Trial 34 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1984938925240719, 'colsample_bytree': 0.617285160213261}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:52,576] Trial 35 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.15342205146364846, 'colsample_bytree': 0.6736289247159732}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:52,818] Trial 36 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.18483545700961063, 'colsample_bytree': 0.5631658012506592}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:53,088] Trial 37 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.14115535709016497, 'colsample_bytree': 0.9577373333575727}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:53,396] Trial 38 finished with value: 0.9553990610328639 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.09296757337068498, 'colsample_bytree': 0.8960960838572454}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:53,536] Trial 39 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.12090949156462359, 'colsample_bytree': 0.6507995492794733}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:53,742] Trial 40 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.15738568844914747, 'colsample_bytree': 0.7959035872203077}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:54,019] Trial 41 finished with value: 0.9741784037558686 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18802226307191017, 'colsample_bytree': 0.5041289430151603}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:54,298] Trial 42 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1762303547212308, 'colsample_bytree': 0.5270563138053709}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:54,589] Trial 43 finished with value: 0.971830985915493 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1918646838995376, 'colsample_bytree': 0.5012219103789087}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:54,818] Trial 44 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.19312596579314265, 'colsample_bytree': 0.5035190487747231}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:55,135] Trial 45 finished with value: 0.971830985915493 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.17211822675950106, 'colsample_bytree': 0.5243163193452611}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:55,291] Trial 46 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.19079474253859224, 'colsample_bytree': 0.5694969253992488}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:55,659] Trial 47 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.06560373154209022, 'colsample_bytree': 0.6015811465481181}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:55,878] Trial 48 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.18174588629569682, 'colsample_bytree': 0.7672094821113753}. Best is trial 31 with value: 0.9741784037558686.\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:5: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:6: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:7: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_14964\\1430847536.py:8: FutureWarning:\n",
      "\n",
      "suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "\n",
      "[I 2025-09-25 16:36:56,213] Trial 49 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1689836158566263, 'colsample_bytree': 0.8495030521377215}. Best is trial 31 with value: 0.9741784037558686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9741784037558686\n",
      "{'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18799187895664138, 'colsample_bytree': 0.5031793942770102}\n"
     ]
    }
   ],
   "source": [
    "# 1. 목적 함수 생성\n",
    "\n",
    "def xgb_optuna_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 3, 10, 1),\n",
    "        'learning_rate' : trial.suggest_uniform('learning_rate', 0.01, 0.2),\n",
    "        'colsample_bytree' : trial.suggest_uniform('colsample_bytree', 0.5, 1)\n",
    "    }\n",
    "    xgb_clf = XGBClassifier(\n",
    "        **params # 딕셔너리 형태는 key값을 속성이름으로, 그 value값을 인자로 받음\n",
    "\n",
    "        # n_estimators = trial.suggest_int('n_estimators', 100, 500, 100),\n",
    "        # max_depth = trial.suggest_int('max_depth', 3, 10, 1),\n",
    "        # learning_rate = trial.suggest_uniform('learning_rate', 0.02, 0.1),\n",
    "        # colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.5, 1)\n",
    "\n",
    "        # 이것도 될듯??\n",
    "    )\n",
    "\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    \n",
    "    return mean_acc\n",
    "\n",
    "# 2. study 객체 만들고 최적화\n",
    "study = optuna.create_study(direction='maximize')\n",
    "# hyperopt와 다르게 minimize 찾을 건지 maximize 찾을 건지 지정 가능\n",
    "study.optimize(xgb_optuna_objective, n_trials=50)\n",
    "\n",
    "# 결과 확인, 출력\n",
    "print(study.best_value)\n",
    "# 0.9741784037558686\n",
    "\n",
    "print(study.best_params)\n",
    "# {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.18799187895664138, 'colsample_bytree': 0.5031793942770102}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebe201",
   "metadata": {},
   "source": [
    "##### HyperOpt vs Optuna\n",
    "- hyperopt\n",
    "{'colsample_bytree': np.float64(0.5626517105133655),\n",
    " 'learning_rate': np.float64(0.19986239480017942),\n",
    " 'max_depth': np.float64(4.0),\n",
    " 'n_estimators': np.float64(500.0)}\n",
    "\n",
    "- optuna\n",
    " {'n_estimators': 500,\n",
    " 'max_depth': 10,\n",
    " 'learning_rate': 0.18799187895664138,\n",
    " 'colsample_bytree': 0.5031793942770102}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt 최적 파라미터 적용: 0.965034965034965\n",
      "Optuna 최적 파라미터 적용: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_hpopt = XGBClassifier(\n",
    "    n_estimators = 500,\n",
    "    max_depth= 4,\n",
    "    learning_rate = 0.2,\n",
    "    colsample_bytree = 0.56\n",
    ")\n",
    "\n",
    "xgb_optuna = XGBClassifier(\n",
    "    n_estimators = 500,\n",
    "    max_depth = 10,\n",
    "    learning_rate = 0.19,\n",
    "    colsample_bytree = 0.50\n",
    ")\n",
    "\n",
    "xgb_hpopt.fit(X_train, y_train)\n",
    "xgb_optuna.fit(X_train, y_train)\n",
    "\n",
    "hpopt_pred = xgb_hpopt.predict(X_test)\n",
    "optuna_pred = xgb_optuna.predict(X_test)\n",
    "\n",
    "print(f'HyperOpt 최적 파라미터 적용: {accuracy_score(y_test, hpopt_pred)}')\n",
    "print(f'Optuna 최적 파라미터 적용: {accuracy_score(y_test, optuna_pred)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
